{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d223e163",
   "metadata": {},
   "source": [
    "# Input and one Dense Layer, own weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe30375",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8259f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 11:42:04.607068: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-25 11:42:06.372935: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-25 11:42:06.372979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-25 11:42:06.379196: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-25 11:42:07.443911: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-25 11:42:07.446444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-25 11:42:44.701164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import h5py\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras import quantized_bits\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "model_path = f\"/eos/project/c/cms-l1ml/public/Pawel/axol1tl_model.h5\"\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=co)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c90bd8",
   "metadata": {},
   "source": [
    "### Prepare data for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6820b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80799b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_quantizer = quantized_bits(14, 5, alpha=1)\n",
    "output_quantizer = quantized_bits(18,13,alpha=1)\n",
    "bias_quantizer = quantized_bits(18,12,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = \n",
    "\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "X_flat = input_quantizer(X_flat)\n",
    "X_flat.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957fe795",
   "metadata": {},
   "source": [
    "### Fragmentary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e691f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fragm_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 57)]              0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 29)                1682      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1682 (6.57 KB)\n",
      "Trainable params: 1682 (6.57 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fragm_model = tf.keras.Model(inputs=model.layers[0].input, outputs=model.layers[1].output, name='fragm_model')\n",
    "fragm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ad484",
   "metadata": {},
   "source": [
    "### Conversion into a hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dcc41ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 57]], output shape: [None, 29]\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(\n",
    "    fragm_model,\n",
    "    granularity='name', \n",
    "    default_precision='fixed<14,7>',\n",
    "    backend='Vitis')\n",
    "print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68c8c0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 57]], output shape: [None, 29]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    fragm_model, hls_config=hls_config, backend='Vitis',\n",
    "    output_dir='./hls_fragm_0_1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6aca682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dacc39e",
   "metadata": {},
   "source": [
    "### Compare predictions for the QKeras and HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b10cc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875],\n",
       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
       "        -5.5546875, -5.5546875]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = numpy.full((2048,57), -5.554452 ,dtype=float)\n",
    "X = input_quantizer(X)\n",
    "X = X.numpy().reshape(X.shape[0], -1)\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "06a83c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 791us/step\n"
     ]
    }
   ],
   "source": [
    "pred_qkeras = fragm_model.predict(X)\n",
    "pred_hls = hls_model.predict(numpy.ascontiguousarray(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b942cf",
   "metadata": {},
   "source": [
    "Both shapes (2048,29) and dtypes (float32) consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18a50b",
   "metadata": {},
   "source": [
    "Differences are mostly 0.0625 (0.0001)$_2$, found also 0.125 (0.001)$_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7ba5c62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625],\n",
       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
       "         0.5625]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_qkeras[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a84958ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.1875, 0.125 , 0.    , 0.125 , 0.125 , 0.125 , 0.    ,\n",
       "        0.    , 0.1875, 0.125 , 0.125 , 0.1875, 0.    , 0.    , 0.    ,\n",
       "        0.1875, 0.1875, 0.    , 0.1875, 0.125 , 0.    , 0.1875, 0.    ,\n",
       "        0.    , 0.1875, 0.1875, 0.1875, 0.125 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = numpy.random.randint(0,2048, 1)\n",
    "(pred_qkeras[i]-pred_hls[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
