{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5410c6bb",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff00aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 22:20:03.804732: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-04 22:20:03.850807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-04 22:20:03.851085: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-04 22:20:03.851126: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-04 22:20:03.860343: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-04 22:20:03.860981: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-04 22:20:14.898170: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras import quantized_bits\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "model_path = f\"/eos/project/c/cms-l1ml/public/Pawel/axol1tl_model.h5\"\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1ee73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"/eos/project/c/cms-l1ml/public/Pawel/complete.h5\"\n",
    "data_file = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff97dd0",
   "metadata": {},
   "source": [
    "### Copy weights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3af7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weights = data_file['model']['trimmed_encoder']['model_weights']\n",
    "for layer in iter(model.layers):\n",
    "    #print(layer.name)\n",
    "    if layer.name in ('input_1','subtract','dot'): continue\n",
    "\n",
    "    if layer.name == 'q_dense_4':\n",
    "        weights_group = ds_weights['q_dense_4']['variational_auto_encoder']['vae__encoder']['q_dense_4']\n",
    "        layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))\n",
    "        continue\n",
    "\n",
    "    weights_group = ds_weights[layer.name][layer.name]\n",
    "    layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dc122",
   "metadata": {},
   "source": [
    "### Check the QKeras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 57)]                 0         []                            \n",
      "                                                                                                  \n",
      " q_dense (QDense)            (None, 29)                   1682      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " q_dense_1 (QDense)          (None, 10)                   300       ['q_dense[0][0]']             \n",
      "                                                                                                  \n",
      " q_dense_2 (QDense)          (None, 9)                    99        ['q_dense_1[0][0]']           \n",
      "                                                                                                  \n",
      " q_dense_3 (QDense)          (None, 6)                    60        ['q_dense_2[0][0]']           \n",
      "                                                                                                  \n",
      " q_dense_4 (QDense)          (None, 4)                    28        ['q_dense_3[0][0]']           \n",
      "                                                                                                  \n",
      " q_dense_6 (QDense)          (None, 6)                    30        ['q_dense_4[0][0]']           \n",
      "                                                                                                  \n",
      " q_dense_7 (QDense)          (None, 9)                    63        ['q_dense_6[0][0]']           \n",
      "                                                                                                  \n",
      " q_dense_8 (QDense)          (None, 10)                   100       ['q_dense_7[0][0]']           \n",
      "                                                                                                  \n",
      " subtract (Subtract)         (None, 10)                   0         ['q_dense_8[0][0]',           \n",
      "                                                                     'q_dense_1[0][0]']           \n",
      "                                                                                                  \n",
      " dot (Dot)                   (None, 1)                    0         ['subtract[0][0]',            \n",
      "                                                                     'subtract[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2362 (9.23 KB)\n",
      "Trainable params: 2362 (9.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d246fc",
   "metadata": {},
   "source": [
    "### Conversion to a QONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee98b47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "2025-09-04 22:22:27.248711: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2025-09-04 22:22:27.248891: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-09-04 22:22:27.415575: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2025-09-04 22:22:27.416366: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/qonnx/transformation/infer_data_layouts.py:136: UserWarning: Assuming 2D input is NC\n",
      "  warnings.warn(\"Assuming 2D input is NC\")\n"
     ]
    }
   ],
   "source": [
    "import qonnx.core.onnx_exec as oxe\n",
    "from qonnx.converters import from_keras\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "qonnx_model, external_storage = from_keras(model)\n",
    "qonnx_model = ModelWrapper(qonnx_model)\n",
    "qonnx_model = qonnx_model.transform(InferShapes())\n",
    "qonnx_model = qonnx_model.transform(InferDataLayouts())\n",
    "qonnx_model = qonnx_model.transform(InferDataTypes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41287a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "qonnx_model.save(\"qonnx_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d111bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Quant_0 ['Quant_0_param0', 'Quant_0_param1', 'Quant_0_param2', 'Quant_0_param3']\n",
      "1 Quant_1 ['Quant_1_param0', 'Quant_1_param1', 'Quant_1_param2', 'Quant_1_param3']\n",
      "2 Quant_2 ['Quant_2_param0', 'Quant_2_param1', 'Quant_2_param2', 'Quant_2_param3']\n",
      "3 Quant_3 ['Quant_3_param0', 'Quant_3_param1', 'Quant_3_param2', 'Quant_3_param3']\n",
      "4 Quant_4 ['Quant_4_param0', 'Quant_4_param1', 'Quant_4_param2', 'Quant_4_param3']\n",
      "5 Quant_5 ['Quant_5_param0', 'Quant_5_param1', 'Quant_5_param2', 'Quant_5_param3']\n",
      "6 Quant_6 ['Quant_6_param0', 'Quant_6_param1', 'Quant_6_param2', 'Quant_6_param3']\n",
      "7 Quant_7 ['Quant_7_param0', 'Quant_7_param1', 'Quant_7_param2', 'Quant_7_param3']\n",
      "8 Quant_8 ['Quant_8_param0', 'Quant_8_param1', 'Quant_8_param2', 'Quant_8_param3']\n",
      "9 Quant_9 ['Quant_9_param0', 'Quant_9_param1', 'Quant_9_param2', 'Quant_9_param3']\n",
      "10 Quant_10 ['Quant_10_param0', 'Quant_10_param1', 'Quant_10_param2', 'Quant_10_param3']\n",
      "11 Quant_11 ['Quant_11_param0', 'Quant_11_param1', 'Quant_11_param2', 'Quant_11_param3']\n",
      "12 Quant_12 ['Quant_12_param0', 'Quant_12_param1', 'Quant_12_param2', 'Quant_12_param3']\n",
      "13 Quant_13 ['Quant_13_param0', 'Quant_13_param1', 'Quant_13_param2', 'Quant_13_param3']\n",
      "14 Quant_14 ['Quant_14_param0', 'Quant_14_param1', 'Quant_14_param2', 'Quant_14_param3']\n",
      "15 Quant_15 ['Quant_15_param0', 'Quant_15_param1', 'Quant_15_param2', 'Quant_15_param3']\n",
      "16 MatMul_0 ['global_in', 'Quant_14_out0']\n",
      "17 Add_0 ['MatMul_0_out0', 'Quant_15_out0']\n",
      "18 Quant_16 ['Add_0_out0', 'Quant_16_param0', 'Quant_16_param1', 'Quant_16_param2']\n",
      "19 Relu_0 ['Quant_16_out0']\n",
      "20 Quant_17 ['Relu_0_out0', 'Quant_17_param0', 'Quant_17_param1', 'Quant_17_param2']\n",
      "21 MatMul_1 ['Quant_17_out0', 'Quant_12_out0']\n",
      "22 Add_1 ['MatMul_1_out0', 'Quant_13_out0']\n",
      "23 Quant_18 ['Add_1_out0', 'Quant_18_param0', 'Quant_18_param1', 'Quant_18_param2']\n",
      "24 Relu_1 ['Quant_18_out0']\n",
      "25 Quant_19 ['Relu_1_out0', 'Quant_19_param0', 'Quant_19_param1', 'Quant_19_param2']\n",
      "26 MatMul_2 ['Quant_19_out0', 'Quant_10_out0']\n",
      "27 Add_2 ['MatMul_2_out0', 'Quant_11_out0']\n",
      "28 Quant_20 ['Add_2_out0', 'Quant_20_param0', 'Quant_20_param1', 'Quant_20_param2']\n",
      "29 Relu_2 ['Quant_20_out0']\n",
      "30 Quant_21 ['Relu_2_out0', 'Quant_21_param0', 'Quant_21_param1', 'Quant_21_param2']\n",
      "31 MatMul_3 ['Quant_21_out0', 'Quant_8_out0']\n",
      "32 Add_3 ['MatMul_3_out0', 'Quant_9_out0']\n",
      "33 Quant_22 ['Add_3_out0', 'Quant_22_param0', 'Quant_22_param1', 'Quant_22_param2']\n",
      "34 Relu_3 ['Quant_22_out0']\n",
      "35 Quant_23 ['Relu_3_out0', 'Quant_23_param0', 'Quant_23_param1', 'Quant_23_param2']\n",
      "36 MatMul_4 ['Quant_23_out0', 'Quant_6_out0']\n",
      "37 Add_4 ['MatMul_4_out0', 'Quant_7_out0']\n",
      "38 MatMul_5 ['Add_4_out0', 'Quant_4_out0']\n",
      "39 Add_5 ['MatMul_5_out0', 'Quant_5_out0']\n",
      "40 Quant_24 ['Add_5_out0', 'Quant_24_param0', 'Quant_24_param1', 'Quant_24_param2']\n",
      "41 Relu_4 ['Quant_24_out0']\n",
      "42 Quant_25 ['Relu_4_out0', 'Quant_25_param0', 'Quant_25_param1', 'Quant_25_param2']\n",
      "43 MatMul_6 ['Quant_25_out0', 'Quant_2_out0']\n",
      "44 Add_6 ['MatMul_6_out0', 'Quant_3_out0']\n",
      "45 Quant_26 ['Add_6_out0', 'Quant_26_param0', 'Quant_26_param1', 'Quant_26_param2']\n",
      "46 Relu_5 ['Quant_26_out0']\n",
      "47 Quant_27 ['Relu_5_out0', 'Quant_27_param0', 'Quant_27_param1', 'Quant_27_param2']\n",
      "48 MatMul_7 ['Quant_27_out0', 'Quant_0_out0']\n",
      "49 Add_7 ['MatMul_7_out0', 'Quant_1_out0']\n",
      "50 Sub_0 ['Add_7_out0', 'Quant_19_out0']\n",
      "51 Unsqueeze_0 ['Sub_0_out0', 'Unsqueeze_0_param0']\n",
      "52 Unsqueeze_1 ['Sub_0_out0', 'Unsqueeze_1_param0']\n",
      "53 MatMul_8 ['Unsqueeze_1_out0', 'Unsqueeze_0_out0']\n",
      "54 Squeeze_0 ['MatMul_8_out0', 'Squeeze_0_param0']\n",
      "55 Identity_0 ['Squeeze_0_out0']\n",
      "56 Identity_1 ['Identity_0_out0']\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(qonnx_model.model.graph.node):\n",
    "    print(i, node.name, node.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd1cd3",
   "metadata": {},
   "source": [
    "### Convert the QONNX model into a HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3d44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qonnx_model = qonnx_model.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba17298",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n"
     ]
    }
   ],
   "source": [
    "from hls4ml.utils.config import config_from_onnx_model\n",
    "from hls4ml.converters import convert_from_onnx_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677b662",
   "metadata": {},
   "source": [
    "from qonnx.custom_op.general import quant\n",
    "\n",
    "qonnx_model = quant.Quant.make_shape_compatible_op()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b109a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_config = config_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    granularity='name',\n",
    "    backend='Vitis',\n",
    "    default_precision='fixed<16,6>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "478d9139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model ...\n",
      "Output layers:  ['Identity_1']\n",
      "Input shape: [None, 57]\n",
      "Topology:\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ERROR: Unsupported operation type: Quant",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m qonnx_model \u001b[38;5;241m=\u001b[39m qonnx_model\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m----> 2\u001b[0m hls_model \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_from_onnx_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqonnx_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrom_qonnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mio_stream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# default is 'io_parallel'\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVitis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhls_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m hls_model\u001b[38;5;241m.\u001b[39mcompile()\n",
      "File \u001b[0;32m~/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/__init__.py:366\u001b[0m, in \u001b[0;36mconvert_from_onnx_model\u001b[0;34m(model, output_dir, project_name, input_data_tb, output_data_tb, backend, hls_config, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHLSConfig\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _check_model_config(model_config)\n\u001b[1;32m    364\u001b[0m _check_hls_config(config, hls_config)\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43monnx_to_hls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/onnx_to_hls.py:281\u001b[0m, in \u001b[0;36monnx_to_hls\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnode:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_layers:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mERROR: Unsupported operation type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mop_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# If not the first layer then input shape is taken from last layer's output\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_counter \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mException\u001b[0m: ERROR: Unsupported operation type: Quant"
     ]
    }
   ],
   "source": [
    "qonnx_model = qonnx_model.cleanup()\n",
    "hls_model = convert_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    output_dir='from_qonnx',\n",
    "    io_type='io_stream',    # default is 'io_parallel'\n",
    "    backend='Vitis',\n",
    "    hls_config=hls_config,\n",
    ")\n",
    "\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538bd60d",
   "metadata": {},
   "source": [
    "File ~/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/onnx_to_hls.py:231, in onnx_to_hls(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
