{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8259f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-15 10:46:16.570214: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-15 10:46:16.608278: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-15 10:46:16.608351: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-15 10:46:16.608403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-15 10:46:16.617247: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-15 10:46:16.617977: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-15 10:46:31.521759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import h5py\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras import quantized_bits\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "model_path = f\"/eos/project/c/cms-l1ml/public/Pawel/axol1tl_model.h5\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=co)\n",
    "#model_config = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc05754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"/eos/project/c/cms-l1ml/public/Pawel/complete.h5\"\n",
    "data_file = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ed723",
   "metadata": {},
   "source": [
    "Copying weights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile() #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b78776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weights = data_file['model']['trimmed_encoder']['model_weights']\n",
    "for layer in iter(model.layers):\n",
    "    #print(layer.name)\n",
    "    if layer.name in ('input_1','subtract','dot'): continue\n",
    "\n",
    "    if layer.name == 'q_dense_4':\n",
    "        weights_group = ds_weights['q_dense_4']['variational_auto_encoder']['vae__encoder']['q_dense_4']\n",
    "        layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))\n",
    "        continue\n",
    "\n",
    "    weights_group = ds_weights[layer.name][layer.name]\n",
    "    layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff01d9",
   "metadata": {},
   "source": [
    "Background prediction (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76461109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_file['data'][\"Background_data\"][\"Test\"][\"DATA\"][:]\n",
    "scale_data = data_file['data']['Normalisation']['norm_scale'][:].flatten()\n",
    "offset_data =  data_file['data']['Normalisation']['norm_bias'][:].flatten()\n",
    "\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "X_int = (X_flat * scale_data) + offset_data\n",
    "X_flat_int = X_int.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779e08ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer = quantized_bits(bits=14, integer=7)\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a843dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:  25%|██▌       | 2/8 [00:00<00:00, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:  50%|█████     | 4/8 [00:00<00:00, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:  75%|███████▌  | 6/8 [00:00<00:00, 16.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds: 100%|██████████| 8/8 [00:00<00:00, 16.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 128\n",
    "predictions = []\n",
    "\n",
    "for start in tqdm(range(0, 1024, batch_size), desc=\"Qkeras preds\"):\n",
    "        end = min(start + batch_size, X_flat_int.shape[0])\n",
    "        X_for_qk = X_flat_int[start:end].astype('float')\n",
    "        X_biased = quantizer(X_for_qk - offset_data).numpy().astype('float')\n",
    "        X_scaled = quantizer(X_biased / scale_data)\n",
    "        X_scaled_quantized_2 = quantizer(X_scaled)\n",
    "        \n",
    "        pred = model.predict(X_scaled_quantized_2)\n",
    "        quantized_pred = quantizer(pred)\n",
    "        predictions.append(quantized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d977ef51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 1), dtype=float32, numpy=\n",
       "array([[ 4.09375 ],\n",
       "       [ 0.953125],\n",
       "       [ 1.734375],\n",
       "       [ 0.921875],\n",
       "       [ 3.359375],\n",
       "       [ 3.3125  ],\n",
       "       [ 3.125   ],\n",
       "       [ 2.21875 ],\n",
       "       [ 1.046875],\n",
       "       [ 2.515625],\n",
       "       [ 1.140625],\n",
       "       [ 0.34375 ],\n",
       "       [ 4.03125 ],\n",
       "       [ 1.015625],\n",
       "       [ 9.40625 ],\n",
       "       [ 1.078125],\n",
       "       [ 2.546875],\n",
       "       [ 1.125   ],\n",
       "       [ 0.78125 ],\n",
       "       [ 1.671875],\n",
       "       [ 1.421875],\n",
       "       [ 2.46875 ],\n",
       "       [ 3.21875 ],\n",
       "       [ 1.40625 ],\n",
       "       [ 1.8125  ],\n",
       "       [ 3.15625 ],\n",
       "       [ 2.9375  ],\n",
       "       [ 1.515625],\n",
       "       [ 1.6875  ],\n",
       "       [ 2.21875 ],\n",
       "       [ 1.1875  ],\n",
       "       [ 1.0625  ],\n",
       "       [ 1.046875],\n",
       "       [ 1.03125 ],\n",
       "       [ 1.1875  ],\n",
       "       [ 1.25    ],\n",
       "       [ 1.1875  ],\n",
       "       [ 2.234375],\n",
       "       [ 2.03125 ],\n",
       "       [ 1.734375],\n",
       "       [ 1.53125 ],\n",
       "       [ 0.984375],\n",
       "       [ 2.609375],\n",
       "       [ 1.5     ],\n",
       "       [ 1.234375],\n",
       "       [ 1.390625],\n",
       "       [ 3.5625  ],\n",
       "       [ 1.5     ],\n",
       "       [ 0.90625 ],\n",
       "       [ 2.265625],\n",
       "       [ 1.40625 ],\n",
       "       [ 2.421875],\n",
       "       [ 3.65625 ],\n",
       "       [ 1.21875 ],\n",
       "       [ 1.140625],\n",
       "       [ 1.625   ],\n",
       "       [ 1.1875  ],\n",
       "       [ 1.34375 ],\n",
       "       [ 2.34375 ],\n",
       "       [ 1.6875  ],\n",
       "       [ 1.671875],\n",
       "       [ 2.890625],\n",
       "       [ 1.0625  ],\n",
       "       [ 0.953125],\n",
       "       [ 2.984375],\n",
       "       [ 1.953125],\n",
       "       [ 4.34375 ],\n",
       "       [ 1.421875],\n",
       "       [ 2.6875  ],\n",
       "       [ 2.4375  ],\n",
       "       [ 2.515625],\n",
       "       [ 0.71875 ],\n",
       "       [ 1.3125  ],\n",
       "       [ 0.484375],\n",
       "       [ 6.203125],\n",
       "       [ 0.625   ],\n",
       "       [ 1.34375 ],\n",
       "       [ 0.71875 ],\n",
       "       [ 1.5     ],\n",
       "       [ 0.890625],\n",
       "       [ 1.609375],\n",
       "       [ 2.234375],\n",
       "       [ 2.765625],\n",
       "       [ 3.109375],\n",
       "       [ 0.859375],\n",
       "       [ 1.96875 ],\n",
       "       [ 2.0625  ],\n",
       "       [ 2.375   ],\n",
       "       [ 0.40625 ],\n",
       "       [ 2.125   ],\n",
       "       [ 1.890625],\n",
       "       [ 0.859375],\n",
       "       [ 0.796875],\n",
       "       [ 2.953125],\n",
       "       [ 2.390625],\n",
       "       [ 0.546875],\n",
       "       [ 1.515625],\n",
       "       [ 3.390625],\n",
       "       [ 0.9375  ],\n",
       "       [ 8.109375],\n",
       "       [ 6.1875  ],\n",
       "       [ 1.5     ],\n",
       "       [ 2.125   ],\n",
       "       [ 1.109375],\n",
       "       [ 4.796875],\n",
       "       [ 3.703125],\n",
       "       [ 2.484375],\n",
       "       [ 0.4375  ],\n",
       "       [ 2.5     ],\n",
       "       [ 4.140625],\n",
       "       [ 1.5     ],\n",
       "       [ 0.671875],\n",
       "       [ 1.015625],\n",
       "       [ 2.765625],\n",
       "       [ 1.78125 ],\n",
       "       [ 2.46875 ],\n",
       "       [ 0.875   ],\n",
       "       [ 1.65625 ],\n",
       "       [ 0.4375  ],\n",
       "       [11.890625],\n",
       "       [ 1.890625],\n",
       "       [ 1.515625],\n",
       "       [ 3.15625 ],\n",
       "       [ 0.625   ],\n",
       "       [ 0.59375 ],\n",
       "       [ 2.328125],\n",
       "       [ 3.921875],\n",
       "       [ 1.109375]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c07fc",
   "metadata": {},
   "source": [
    "Signal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f7d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_file['data'][\"Signal_data\"][\"GluGluHToBB_M-125\"][\"DATA\"][:]\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "X_int = (X_flat * scale_data) + offset_data\n",
    "X_flat_int = X_int.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1ec412",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_predictions = numpy.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18339ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127.984375],\n",
       "       [107.5     ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [111.921875],\n",
       "       [105.609375],\n",
       "       [110.625   ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [112.9375  ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [107.453125],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 81.125   ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 57.359375],\n",
       "       [ 36.3125  ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [107.953125],\n",
       "       [127.984375],\n",
       "       [ 49.875   ],\n",
       "       [ 66.921875],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 33.8125  ],\n",
       "       [ 43.140625],\n",
       "       [ 89.96875 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 74.421875],\n",
       "       [ 35.5625  ],\n",
       "       [ 74.96875 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [120.484375],\n",
       "       [106.953125],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 59.46875 ],\n",
       "       [127.984375],\n",
       "       [122.859375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [104.75    ],\n",
       "       [127.984375],\n",
       "       [ 49.625   ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [109.296875],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 96.03125 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 40.234375],\n",
       "       [ 59.265625],\n",
       "       [ 76.      ],\n",
       "       [127.984375],\n",
       "       [ 59.328125],\n",
       "       [ 41.203125],\n",
       "       [127.984375],\n",
       "       [ 31.265625],\n",
       "       [127.984375],\n",
       "       [ 64.3125  ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 62.59375 ],\n",
       "       [127.984375],\n",
       "       [ 22.109375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 44.890625],\n",
       "       [ 35.40625 ],\n",
       "       [127.984375],\n",
       "       [ 92.65625 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 20.484375],\n",
       "       [127.984375],\n",
       "       [ 52.609375],\n",
       "       [127.921875],\n",
       "       [127.609375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [122.65625 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [ 40.828125],\n",
       "       [127.984375],\n",
       "       [104.28125 ],\n",
       "       [127.984375],\n",
       "       [127.984375],\n",
       "       [113.5     ],\n",
       "       [127.984375],\n",
       "       [ 93.3125  ],\n",
       "       [127.984375],\n",
       "       [ 74.9375  ],\n",
       "       [ 61.21875 ],\n",
       "       [ 28.3125  ],\n",
       "       [127.984375],\n",
       "       [127.984375]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ad484",
   "metadata": {},
   "source": [
    "Conversion into a hls4ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcc41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(\n",
    "    model,\n",
    "    granularity='name', \n",
    "    default_precision='fixed<14,7>',\n",
    "    backend='Vitis')\n",
    "print(\"-----------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=hls_config, backend='Vitis',\n",
    "    output_dir='./hls_test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b910831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = numpy.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 128\n",
    "predictions_hls = []\n",
    "\n",
    "for start in tqdm(range(0, 1024, batch_size), desc=\"hls preds\"):\n",
    "        end = min(start + batch_size, X_flat_int.shape[0])\n",
    "        X_for_qk = X_flat_int[start:end].astype('float')\n",
    "        X_biased = quantizer(X_for_qk - offset_data).numpy().astype('float')\n",
    "        X_scaled = quantizer(X_biased / scale_data)\n",
    "        X_scaled_quantized_2 = quantizer(X_scaled)\n",
    "        \n",
    "        pred = hls_model.predict(numpy.ascontiguousarray(X_scaled_quantized_2))\n",
    "        quantized_pred = quantizer(pred)\n",
    "        predictions_hls.append(quantized_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0][:,0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8220c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.column_stack((predictions[0][:,0].numpy(),predictions_hls[0][:,0].numpy())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
