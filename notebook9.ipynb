{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc67597",
   "metadata": {},
   "source": [
    "# First notebook with Python3.11\n",
    "## Load the qonnx model and convert it to an hls model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b0989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607ff7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"qonnx_fragm_model.onnx\"\n",
    "qonnx_model = ModelWrapper(model_path)\n",
    "qonnx_model = qonnx_model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fb47d",
   "metadata": {},
   "source": [
    "### Convert to an HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.utils.config import config_from_onnx_model\n",
    "from hls4ml.converters import convert_from_onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4370db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n"
     ]
    }
   ],
   "source": [
    "hls_config = config_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    granularity='name',\n",
    "    backend='Vitis',\n",
    "    default_precision='fixed<16,6>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca263ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': {'default': 'fixed<16,6>'},\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency',\n",
       "  'BramFactor': 1000000000,\n",
       "  'TraceOutput': False},\n",
       " 'LayerName': {'global_in': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_6': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_7': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_8': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_9': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_10': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_11': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_12': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_13': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_14': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_15': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_0': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_16': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_17': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_1': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_18': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_19': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_2': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_20': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_21': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_3': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_22': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_23': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_4': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'MatMul_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_5': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_24': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_25': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_6': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_6': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_26': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_27': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_7': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_7': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Sub_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b30c0b",
   "metadata": {},
   "source": [
    "Custom flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2f39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_config['Flows'] = {'parse_qonnx'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b049412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model ...\n",
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/model/optimizer/passes/move_scales.py:93: UserWarning: Failed to propagate quantization scales down MatMul node; model probably not suppored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qonnx_model = qonnx_model.cleanup()\n",
    "hls_model = convert_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    output_dir='hls_model8',\n",
    "    io_type='io_stream',    # default is 'io_parallel'\n",
    "    backend='Vitis',\n",
    "    hls_config=hls_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1b41c",
   "metadata": {},
   "source": [
    "### Look at the uncompiled HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bad3c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parse_qonnx': {'fuse_quant_with_constant',\n",
       "   'matmul_const_to_dense',\n",
       "   'merge_to_apply_alpha',\n",
       "   'quant_constant_parameters',\n",
       "   'quant_to_activation',\n",
       "   'scale_down_mat_mul'}}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model._applied_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _layer_name in hls_model.graph.keys():\n",
    "    layer_dicts.append(hls_model.graph.get(_layer_name).__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf405c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(hls_model.graph.get(_layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dicts[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
