commit 089b9217e605c0c225b14b50eb5a1e16f837a090
Author: Pawel Sajdak <psajdak@lxplus976.cern.ch>
Date:   Tue Aug 26 16:40:09 2025 +0200

    update

diff --git a/notebook5.ipynb b/notebook5.ipynb
index bea4fb8..9226e7b 100644
--- a/notebook5.ipynb
+++ b/notebook5.ipynb
@@ -18,14 +18,14 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "2025-08-20 17:43:47.905117: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
-      "2025-08-20 17:43:47.960080: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
-      "2025-08-20 17:43:47.960133: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
-      "2025-08-20 17:43:47.960193: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
-      "2025-08-20 17:43:47.970643: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
-      "2025-08-20 17:43:47.971153: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
+      "2025-08-25 13:36:30.430449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
+      "2025-08-25 13:36:32.035677: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
+      "2025-08-25 13:36:32.035748: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
+      "2025-08-25 13:36:32.042045: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
+      "2025-08-25 13:36:32.901758: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
+      "2025-08-25 13:36:32.905337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
       "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
-      "2025-08-20 17:43:58.160441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
+      "2025-08-25 13:37:10.794583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
       "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
       "  backends.update(_get_backends(\"networkx.backends\"))\n"
      ]
@@ -111,29 +111,29 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 10,
    "id": "80799b66",
    "metadata": {},
    "outputs": [],
    "source": [
-    "input_quantizer = quantized_bits(14, 5, alpha=1)\n",
+    "input_quantizer = quantized_bits(14, 6, alpha=1)\n",
     "output_quantizer = quantized_bits(18,13,alpha=1)\n",
     "bias_quantizer = quantized_bits(18,12,alpha=1)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 11,
    "id": "7d07e5c4",
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "tf.float32"
+       "dtype('float64')"
       ]
      },
-     "execution_count": 5,
+     "execution_count": 11,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -142,7 +142,7 @@
     "X = data_file['data'][\"Background_data\"][\"Test\"][\"DATA\"][:2048]\n",
     "\n",
     "X_flat = X.reshape(X.shape[0], -1)\n",
-    "X_flat = input_quantizer(X_flat)\n",
+    "#X_flat = input_quantizer(X_flat)\n",
     "X_flat.dtype"
    ]
   },
@@ -156,7 +156,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 6,
    "id": "e691f8b7",
    "metadata": {},
    "outputs": [
@@ -190,19 +190,64 @@
    "id": "3e6ad484",
    "metadata": {},
    "source": [
-    "### Conversion into a hls4ml model"
+    "## Conversion into a hls4ml model"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "fd8481c3",
+   "metadata": {},
+   "source": [
+    "### HLS_config"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 17,
+   "id": "fde85c96",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'kernel_quantizer': 'quantized_bits(6,2,0,alpha=1)',\n",
+       " 'bias_quantizer': 'quantized_bits(10,6,0,alpha=1)',\n",
+       " 'activation': 'quantized_relu(10,6)',\n",
+       " 'units': '29'}"
+      ]
+     },
+     "execution_count": 17,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "fragm_model.layers[1].get_quantization_config()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 8,
    "id": "9dcc41ea",
    "metadata": {},
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
+      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
+      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
+      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
+      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
+      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
+      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
       "Interpreting Model\n",
       "Topology:\n",
       "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
@@ -232,7 +277,53 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 9,
+   "id": "3dd206d4",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'Model': {'Precision': 'fixed<14,7>',\n",
+       "  'ReuseFactor': 1,\n",
+       "  'Strategy': 'Latency',\n",
+       "  'BramFactor': 1000000000,\n",
+       "  'TraceOutput': False},\n",
+       " 'LayerName': {'input_1': {'Trace': False,\n",
+       "   'Precision': {'result': 'fixed<14,7>'}},\n",
+       "  'q_dense': {'Trace': False,\n",
+       "   'Precision': {'result': 'fixed<14,7>',\n",
+       "    'weight': 'fixed<6,3>',\n",
+       "    'bias': 'fixed<10,7>',\n",
+       "    'accum': 'fixed<14,7>'},\n",
+       "   'ReuseFactor': 1},\n",
+       "  'q_dense_quantized_relu': {'Trace': False,\n",
+       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
+       "    'table': 'fixed<18,8>'},\n",
+       "   'ReuseFactor': 1,\n",
+       "   'TableSize': 1024}}}"
+      ]
+     },
+     "execution_count": 9,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "hls_config"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "f3f6e945",
+   "metadata": {},
+   "source": [
+    "### Conversion"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
    "id": "68c8c0c3",
    "metadata": {},
    "outputs": [
@@ -257,7 +348,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 12,
    "id": "b6aca682",
    "metadata": {},
    "outputs": [
@@ -273,6 +364,8 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
+      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
+      "  saving_api.save_model(\n",
       "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
      ]
     },
@@ -298,7 +391,150 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 126,
+   "id": "2b10cc5a",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "array([[-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875],\n",
+       "       [-5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875, -5.5546875, -5.5546875, -5.5546875,\n",
+       "        -5.5546875, -5.5546875]], dtype=float32)"
+      ]
+     },
+     "execution_count": 126,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "X = numpy.full((2048,57), -5.554452 ,dtype=float)\n",
+    "X = input_quantizer(X)\n",
+    "X = X.numpy().reshape(X.shape[0], -1)\n",
+    "X[:10]"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 127,
    "id": "06a83c2b",
    "metadata": {},
    "outputs": [
@@ -306,13 +542,13 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "64/64 [==============================] - 0s 2ms/step\n"
+      "64/64 [==============================] - 0s 791us/step\n"
      ]
     }
    ],
    "source": [
-    "pred_qkeras = fragm_model.predict(X_flat)\n",
-    "pred_hls = hls_model.predict(numpy.ascontiguousarray(X_flat))"
+    "pred_qkeras = fragm_model.predict(X)\n",
+    "pred_hls = hls_model.predict(numpy.ascontiguousarray(X))"
    ]
   },
   {
@@ -323,32 +559,107 @@
     "Both shapes (2048,29) and dtypes (float32) consistent"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "1a18a50b",
+   "metadata": {},
+   "source": [
+    "Differences are mostly 0.0625 (0.0001)$_2$, found also 0.125 (0.001)$_2$"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 130,
+   "id": "7ba5c62b",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "array([[ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625],\n",
+       "       [ 0.    ,  8.3125,  6.25  ,  0.    ,  5.8125,  7.3125,  9.    ,\n",
+       "         0.    ,  0.    ,  3.75  ,  9.    ,  1.9375, 13.3125,  0.    ,\n",
+       "         0.    ,  0.    ,  5.6875,  4.1875,  0.    , 21.5   , 20.125 ,\n",
+       "         0.    , 17.5   ,  0.    ,  0.    , 14.6875, 12.1875,  6.375 ,\n",
+       "         0.5625]], dtype=float32)"
+      ]
+     },
+     "execution_count": 130,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "pred_qkeras[:10]"
+   ]
+  },
   {
    "cell_type": "code",
-   "execution_count": 23,
-   "id": "cfc1a467",
+   "execution_count": 129,
+   "id": "a84958ce",
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "array([[1.625 , 0.625 , 0.75  , 1.1875, 0.5   , 0.75  , 1.5625, 3.6875,\n",
-       "        1.0625, 1.625 , 0.    , 0.    , 0.4375, 2.3125, 1.0625, 0.    ,\n",
-       "        3.6875, 0.    , 0.    , 2.125 , 2.875 , 0.    , 0.    , 1.25  ,\n",
-       "        0.    , 0.125 , 0.125 , 3.875 , 0.    ],\n",
-       "       [1.5625, 0.5625, 0.6875, 1.125 , 0.4375, 0.6875, 1.5   , 3.6875,\n",
-       "        1.    , 1.5625, 0.    , 0.    , 0.375 , 2.25  , 1.0625, 0.    ,\n",
-       "        3.625 , 0.    , 0.    , 2.0625, 2.8125, 0.    , 0.    , 1.1875,\n",
-       "        0.    , 0.0625, 0.0625, 3.8125, 0.    ]], dtype=float32)"
+       "array([[0.    , 0.1875, 0.125 , 0.    , 0.125 , 0.125 , 0.125 , 0.    ,\n",
+       "        0.    , 0.1875, 0.125 , 0.125 , 0.1875, 0.    , 0.    , 0.    ,\n",
+       "        0.1875, 0.1875, 0.    , 0.1875, 0.125 , 0.    , 0.1875, 0.    ,\n",
+       "        0.    , 0.1875, 0.1875, 0.1875, 0.125 ]], dtype=float32)"
       ]
      },
-     "execution_count": 23,
+     "execution_count": 129,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "numpy.vstack((pred_qkeras[0], pred_hls[0]))"
+    "i = numpy.random.randint(0,2048, 1)\n",
+    "(pred_qkeras[i]-pred_hls[i])"
    ]
   }
  ],
