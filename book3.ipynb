{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a18b73",
   "metadata": {},
   "source": [
    "### Info\n",
    "based on notebook3\\\n",
    "conversion of qkeras to hls4ml, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab2513",
   "metadata": {},
   "source": [
    "## Create the hls_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc0d5be",
   "metadata": {},
   "source": [
    "### Load packages and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0a3a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 21:24:12.021007: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-07 21:24:12.055203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-07 21:24:12.055264: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-07 21:24:12.055313: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-07 21:24:12.064319: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-07 21:24:12.064739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-07 21:24:20.305905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras import quantized_bits\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "model_path = f\"/eos/project/c/cms-l1ml/public/Pawel/axol1tl_model.h5\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=co)\n",
    "#model_config = model.get_config()\n",
    "\n",
    "data_path = f\"/eos/project/c/cms-l1ml/public/Pawel/complete.h5\"\n",
    "data_file = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2266868",
   "metadata": {},
   "source": [
    "### Copy weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec905f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weights = data_file['model']['trimmed_encoder']['model_weights']\n",
    "for layer in iter(model.layers):\n",
    "    #print(layer.name)\n",
    "    if layer.name in ('input_1','subtract','dot'): continue\n",
    "\n",
    "    if layer.name == 'q_dense_4':\n",
    "        weights_group = ds_weights['q_dense_4']['variational_auto_encoder']['vae__encoder']['q_dense_4']\n",
    "        layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))\n",
    "        continue\n",
    "\n",
    "    weights_group = ds_weights[layer.name][layer.name]\n",
    "    layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6571c",
   "metadata": {},
   "source": [
    "### Into hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0772ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 57]], output shape: [None, 29]\n",
      "Layer name: q_dense_1, layer type: QDense, input shapes: [[None, 29]], output shape: [None, 10]\n",
      "Layer name: q_dense_2, layer type: QDense, input shapes: [[None, 10]], output shape: [None, 9]\n",
      "Layer name: q_dense_3, layer type: QDense, input shapes: [[None, 9]], output shape: [None, 6]\n",
      "Layer name: q_dense_4, layer type: QDense, input shapes: [[None, 6]], output shape: [None, 4]\n",
      "Layer name: q_dense_6, layer type: QDense, input shapes: [[None, 4]], output shape: [None, 6]\n",
      "Layer name: q_dense_7, layer type: QDense, input shapes: [[None, 6]], output shape: [None, 9]\n",
      "Layer name: q_dense_8, layer type: QDense, input shapes: [[None, 9]], output shape: [None, 10]\n",
      "Layer name: subtract, layer type: Merge, input shapes: [[None, 10], [None, 10]], output shape: [None, 10]\n",
      "Layer name: dot, layer type: Dot, input shapes: [[None, 10], [None, 10]], output shape: [None, 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(\n",
    "    model,\n",
    "    granularity='name', \n",
    "    default_precision='fixed<18,8>',    # like the activation\n",
    "    backend='Vitis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e67cef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': 'fixed<18,8>',\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency',\n",
       "  'BramFactor': 1000000000,\n",
       "  'TraceOutput': False},\n",
       " 'LayerName': {'input_1': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>'}},\n",
       "  'q_dense': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_1': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_1_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_2': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_2_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_3': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_3_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_4': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_4_linear': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>', 'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_6': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_6_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_7': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_7_quantized_relu': {'Trace': False,\n",
       "   'Precision': {'result': 'ufixed<10,6,RND_CONV,SAT>',\n",
       "    'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'q_dense_8': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>',\n",
       "    'weight': 'fixed<6,3>',\n",
       "    'bias': 'fixed<10,7>',\n",
       "    'accum': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1},\n",
       "  'q_dense_8_linear': {'Trace': False,\n",
       "   'Precision': {'result': 'fixed<18,8>', 'table': 'fixed<18,8>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'subtract': {'Trace': True, 'Precision': {'result': 'fixed<18,14>'}},\n",
       "  'dot': {'Trace': True,\n",
       "   'Precision': {'result': 'fixed<18,14>', 'accum': 'fixed<18,14>'},\n",
       "   'ReuseFactor': 1}}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_config['LayerName']['dot']['Precision']['accum'] = 'fixed<18,14>'\n",
    "hls_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fcd9b777",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf \"new_hls_qkeras/\"\n",
    "!rm \"new_hls_qkeras.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbda1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 57]], output shape: [None, 57]\n",
      "Layer name: q_dense, layer type: QDense, input shapes: [[None, 57]], output shape: [None, 29]\n",
      "Layer name: q_dense_1, layer type: QDense, input shapes: [[None, 29]], output shape: [None, 10]\n",
      "Layer name: q_dense_2, layer type: QDense, input shapes: [[None, 10]], output shape: [None, 9]\n",
      "Layer name: q_dense_3, layer type: QDense, input shapes: [[None, 9]], output shape: [None, 6]\n",
      "Layer name: q_dense_4, layer type: QDense, input shapes: [[None, 6]], output shape: [None, 4]\n",
      "Layer name: q_dense_6, layer type: QDense, input shapes: [[None, 4]], output shape: [None, 6]\n",
      "Layer name: q_dense_7, layer type: QDense, input shapes: [[None, 6]], output shape: [None, 9]\n",
      "Layer name: q_dense_8, layer type: QDense, input shapes: [[None, 9]], output shape: [None, 10]\n",
      "Layer name: subtract, layer type: Merge, input shapes: [[None, 10], [None, 10]], output shape: [None, 10]\n",
      "Layer name: dot, layer type: Dot, input shapes: [[None, 10], [None, 10]], output shape: [None, 10]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=hls_config, backend='Vitis',\n",
    "    output_dir='./new_hls_qkeras'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "12a54840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1537d95",
   "metadata": {},
   "source": [
    "## Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d617c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_quantizer = quantized_bits(14, 6, alpha=1)\n",
    "output_quantizer = quantized_bits(18,14,alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20d6a7",
   "metadata": {},
   "source": [
    "Y = data_file['data'][\"Background_data\"][\"Test\"][\"DATA\"]\n",
    "Y.shape[0] = 4511092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "954b6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_file['data'][\"Signal_data\"][\"GluGluHToGG_M-125\"][\"DATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0ff184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194433, 19, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19a676cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'name',\n",
       " 'index',\n",
       " 'inputs',\n",
       " 'outputs',\n",
       " 'attributes',\n",
       " 'weights',\n",
       " 'variables',\n",
       " 'types',\n",
       " 'code',\n",
       " 'channels_last_converted',\n",
       " '_expected_attributes',\n",
       " '_wrapped',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " 'initialize',\n",
       " 'expected_attributes',\n",
       " '__init__',\n",
       " 'class_name',\n",
       " 'set_attr',\n",
       " 'get_attr',\n",
       " '_validate_attributes',\n",
       " '_wrap_precision_to_type',\n",
       " '_set_accum_t',\n",
       " 'get_input_node',\n",
       " 'get_input_variable',\n",
       " 'get_output_use_map',\n",
       " 'get_output_nodes',\n",
       " 'get_output_variable',\n",
       " 'get_weights',\n",
       " 'get_variables',\n",
       " 'add_output_variable',\n",
       " 'add_weights',\n",
       " 'add_bias',\n",
       " 'add_weights_variable',\n",
       " 'get_layer_precision',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.graph.get('dot').__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87384638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hls4ml.backends.fpga.fpga_backend.VitisMerge at 0x7f6fe272a400>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.graph.get('dot').get_input_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "20c9c51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompiling myproject with tracing\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# HLS Tracing\n",
    "trace = hls_model.trace(data[4].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f26acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([164.6875]),\n",
       " {'subtract': array([[ -0.125 ,   0.    ,  -1.25  ,   0.    ,  -2.6875,  -2.875 ,\n",
       "            0.5   , -11.75  ,  -0.1875,  -3.0625]]),\n",
       "  'dot': array([[164.6875]])})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8412c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -0.125      0.03125   -1.203125   0.046875  -2.6875    -2.828125\n",
      "   0.53125  -11.734375  -0.15625   -3.015625]\n",
      "163.783447265625\n"
     ]
    }
   ],
   "source": [
    "vec = np.array([-0.125   ,   0.03125 ,  -1.203125,   0.046875,  -2.6875  ,\n",
    "           -2.828125,   0.53125 , -11.734375,  -0.15625 ,  -3.015625])\n",
    "print(vec)\n",
    "print((vec*vec).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "352ea064",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82218b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(data.shape[0], 2048, False)\n",
    "sample_indices.sort()\n",
    "sample_indices\n",
    "X = data[sample_indices]\n",
    "X_flat = X.reshape(X.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8075b4f4",
   "metadata": {},
   "source": [
    "### HLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d0ebca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [00:04<00:00, 445.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pred_hls = []\n",
    "for i in tqdm(range(0,X_flat.shape[0])):\n",
    "    pred_hls_ = hls_model.predict(input_quantizer(X_flat[i]).numpy())\n",
    "    pred_hls.append(output_quantizer(pred_hls_).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d610141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-103.125]\n",
      " [  93.   ]\n",
      " [  39.375]\n",
      " ...\n",
      " [-116.   ]\n",
      " [-110.   ]\n",
      " [ -87.25 ]]\n"
     ]
    }
   ],
   "source": [
    "pred_hls = np.stack(pred_hls)\n",
    "print(pred_hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7599ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hls = pred_hls.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9693e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./pred_GGHToGG_M125/preds_hls\"+ind,pred_hls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6537f",
   "metadata": {},
   "source": [
    "### QONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ecc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qonnx.core.onnx_exec as oxe\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "\n",
    "qonnx_model = ModelWrapper(\"init_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcc9c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [27:11<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pred_qonnx = []\n",
    "\n",
    "for i in tqdm(range(0, X_flat.shape[0])):\n",
    "    idict = {qonnx_model.graph.input[0].name: input_quantizer(X[i]).numpy().reshape(1,57)}\n",
    "    odict = oxe.execute_onnx(qonnx_model, idict, False)\n",
    "    pred_ = output_quantizer(odict[qonnx_model.graph.output[0].name])\n",
    "    pred_qonnx.append(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7494cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_qonnx_np = np.array(pred_qonnx)\n",
    "pred_qonnx_np.shape\n",
    "pred_qonnx_np = pred_qonnx_np.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b4278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./pred_GGHToGG_M125/preds_qonnx_init\"+ind,pred_qonnx_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63faafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "del qonnx_model\n",
    "qonnx_model = ModelWrapper(\"mod_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3e5b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2048/2048 [37:34<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pred_qonnx = []\n",
    "\n",
    "for i in tqdm(range(0, X_flat.shape[0])):\n",
    "    idict = {qonnx_model.graph.input[0].name: input_quantizer(X[i]).numpy().reshape(1,57)}\n",
    "    odict = oxe.execute_onnx(qonnx_model, idict, False)\n",
    "    pred_ = output_quantizer(odict[qonnx_model.graph.output[0].name])\n",
    "    pred_qonnx.append(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d29d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_qonnx_np = np.array(pred_qonnx)\n",
    "pred_qonnx_np.shape\n",
    "pred_qonnx_np = pred_qonnx_np.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d2d1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./pred_GGHToGG_M125/preds_qonnx_mod\"+ind,pred_qonnx_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefb989",
   "metadata": {},
   "source": [
    "### qKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2f54e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "qk_pred_ = model.predict(input_quantizer(X_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf66d8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_pred = output_quantizer(qk_pred_)\n",
    "qk_pred = qk_pred.numpy()\n",
    "qk_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61261333",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./pred_GGHToGG_M125/preds_qkeras\"+ind, qk_pred.reshape(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
