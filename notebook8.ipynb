{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc67597",
   "metadata": {},
   "source": [
    "# First notebook with Python3.11\n",
    "## Load the qonnx model and convert it to an hls model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b0989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607ff7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"qonnx_fragm_model.onnx\"\n",
    "qonnx_model = ModelWrapper(model_path)\n",
    "qonnx_model = qonnx_model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e7a4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qonnx.core.modelwrapper.ModelWrapper at 0x7f8c643f7e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qonnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407cce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Quant_0 ['Quant_0_param0', 'Quant_0_param1', 'Quant_0_param2', 'Quant_0_param3']\n",
      "1 Quant_1 ['Quant_1_param0', 'Quant_1_param1', 'Quant_1_param2', 'Quant_1_param3']\n",
      "2 Quant_2 ['Quant_2_param0', 'Quant_2_param1', 'Quant_2_param2', 'Quant_2_param3']\n",
      "3 Quant_3 ['Quant_3_param0', 'Quant_3_param1', 'Quant_3_param2', 'Quant_3_param3']\n",
      "4 Quant_4 ['Quant_4_param0', 'Quant_4_param1', 'Quant_4_param2', 'Quant_4_param3']\n",
      "5 Quant_5 ['Quant_5_param0', 'Quant_5_param1', 'Quant_5_param2', 'Quant_5_param3']\n",
      "6 Quant_6 ['Quant_6_param0', 'Quant_6_param1', 'Quant_6_param2', 'Quant_6_param3']\n",
      "7 Quant_7 ['Quant_7_param0', 'Quant_7_param1', 'Quant_7_param2', 'Quant_7_param3']\n",
      "8 Quant_8 ['Quant_8_param0', 'Quant_8_param1', 'Quant_8_param2', 'Quant_8_param3']\n",
      "9 Quant_9 ['Quant_9_param0', 'Quant_9_param1', 'Quant_9_param2', 'Quant_9_param3']\n",
      "10 Quant_10 ['Quant_10_param0', 'Quant_10_param1', 'Quant_10_param2', 'Quant_10_param3']\n",
      "11 Quant_11 ['Quant_11_param0', 'Quant_11_param1', 'Quant_11_param2', 'Quant_11_param3']\n",
      "12 Quant_12 ['Quant_12_param0', 'Quant_12_param1', 'Quant_12_param2', 'Quant_12_param3']\n",
      "13 Quant_13 ['Quant_13_param0', 'Quant_13_param1', 'Quant_13_param2', 'Quant_13_param3']\n",
      "14 Quant_14 ['Quant_14_param0', 'Quant_14_param1', 'Quant_14_param2', 'Quant_14_param3']\n",
      "15 Quant_15 ['Quant_15_param0', 'Quant_15_param1', 'Quant_15_param2', 'Quant_15_param3']\n",
      "16 MatMul_0 ['global_in', 'Quant_14_out0']\n",
      "17 Add_0 ['MatMul_0_out0', 'Quant_15_out0']\n",
      "18 Quant_16 ['Add_0_out0', 'Quant_16_param0', 'Quant_16_param1', 'Quant_16_param2']\n",
      "19 Relu_0 ['Quant_16_out0']\n",
      "20 Quant_17 ['Relu_0_out0', 'Quant_17_param0', 'Quant_17_param1', 'Quant_17_param2']\n",
      "21 MatMul_1 ['Quant_17_out0', 'Quant_12_out0']\n",
      "22 Add_1 ['MatMul_1_out0', 'Quant_13_out0']\n",
      "23 Quant_18 ['Add_1_out0', 'Quant_18_param0', 'Quant_18_param1', 'Quant_18_param2']\n",
      "24 Relu_1 ['Quant_18_out0']\n",
      "25 Quant_19 ['Relu_1_out0', 'Quant_19_param0', 'Quant_19_param1', 'Quant_19_param2']\n",
      "26 MatMul_2 ['Quant_19_out0', 'Quant_10_out0']\n",
      "27 Add_2 ['MatMul_2_out0', 'Quant_11_out0']\n",
      "28 Quant_20 ['Add_2_out0', 'Quant_20_param0', 'Quant_20_param1', 'Quant_20_param2']\n",
      "29 Relu_2 ['Quant_20_out0']\n",
      "30 Quant_21 ['Relu_2_out0', 'Quant_21_param0', 'Quant_21_param1', 'Quant_21_param2']\n",
      "31 MatMul_3 ['Quant_21_out0', 'Quant_8_out0']\n",
      "32 Add_3 ['MatMul_3_out0', 'Quant_9_out0']\n",
      "33 Quant_22 ['Add_3_out0', 'Quant_22_param0', 'Quant_22_param1', 'Quant_22_param2']\n",
      "34 Relu_3 ['Quant_22_out0']\n",
      "35 Quant_23 ['Relu_3_out0', 'Quant_23_param0', 'Quant_23_param1', 'Quant_23_param2']\n",
      "36 MatMul_4 ['Quant_23_out0', 'Quant_6_out0']\n",
      "37 Add_4 ['MatMul_4_out0', 'Quant_7_out0']\n",
      "38 MatMul_5 ['Add_4_out0', 'Quant_4_out0']\n",
      "39 Add_5 ['MatMul_5_out0', 'Quant_5_out0']\n",
      "40 Quant_24 ['Add_5_out0', 'Quant_24_param0', 'Quant_24_param1', 'Quant_24_param2']\n",
      "41 Relu_4 ['Quant_24_out0']\n",
      "42 Quant_25 ['Relu_4_out0', 'Quant_25_param0', 'Quant_25_param1', 'Quant_25_param2']\n",
      "43 MatMul_6 ['Quant_25_out0', 'Quant_2_out0']\n",
      "44 Add_6 ['MatMul_6_out0', 'Quant_3_out0']\n",
      "45 Quant_26 ['Add_6_out0', 'Quant_26_param0', 'Quant_26_param1', 'Quant_26_param2']\n",
      "46 Relu_5 ['Quant_26_out0']\n",
      "47 Quant_27 ['Relu_5_out0', 'Quant_27_param0', 'Quant_27_param1', 'Quant_27_param2']\n",
      "48 MatMul_7 ['Quant_27_out0', 'Quant_0_out0']\n",
      "49 Add_7 ['MatMul_7_out0', 'Quant_1_out0']\n",
      "50 Sub_0 ['Add_7_out0', 'Quant_19_out0']\n",
      "51 Identity_0 ['Sub_0_out0']\n",
      "52 Identity_1 ['Identity_0_out0']\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(qonnx_model.model.graph.node):\n",
    "    print(i, node.name, node.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fb47d",
   "metadata": {},
   "source": [
    "### Convert to an HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.utils.config import config_from_onnx_model\n",
    "from hls4ml.converters import convert_from_onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4370db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n"
     ]
    }
   ],
   "source": [
    "hls_config = config_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    granularity='name',\n",
    "    backend='Vitis',\n",
    "    default_precision='fixed<16,6>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca263ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': {'default': 'fixed<16,6>'},\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency',\n",
       "  'BramFactor': 1000000000,\n",
       "  'TraceOutput': False},\n",
       " 'LayerName': {'global_in': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_1_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_2_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_3_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_4_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_5_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_6_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_7_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_8_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_9_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_10_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_11_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_12_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_13_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_14_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_15_param3': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_16_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_17_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_18_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_19_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_20_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_21_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_22_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_23_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_24_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_25_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_26_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param0': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param1': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_27_param2': {'Trace': False, 'Precision': {'result': 'auto'}},\n",
       "  'Quant_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_6': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_7': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_8': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_9': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_10': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_11': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_12': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_13': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_14': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Quant_15': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_0': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_16': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_17': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_1': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_18': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_1': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_19': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_2': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_20': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_2': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_21': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_3': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_22': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_3': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_23': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_4': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'MatMul_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_5': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_24': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_4': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_25': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_6': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_6': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Quant_26': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Relu_5': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'},\n",
       "   'ReuseFactor': 1,\n",
       "   'TableSize': 1024},\n",
       "  'Quant_27': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'MatMul_7': {'Trace': False,\n",
       "   'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       "   'ReuseFactor': 1},\n",
       "  'Add_7': {'Trace': False, 'Precision': {'result': 'auto'}, 'ReuseFactor': 1},\n",
       "  'Sub_0': {'Trace': False,\n",
       "   'Precision': {'result': 'auto'},\n",
       "   'ReuseFactor': 1}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b049412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model ...\n",
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/model/optimizer/passes/move_scales.py:93: UserWarning: Failed to propagate quantization scales down MatMul node; model probably not suppored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qonnx_model = qonnx_model.cleanup()\n",
    "hls_model = convert_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    output_dir='from_qonnx_fragm',\n",
    "    io_type='io_stream',    # default is 'io_parallel'\n",
    "    backend='Vitis',\n",
    "    hls_config=hls_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04381572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name: Dense_MatMul_0\n",
      "\n",
      "Layer Configuration:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Trace': False,\n",
       " 'Precision': {'result': 'auto', 'accum': 'auto'},\n",
       " 'ReuseFactor': 1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the second layer\n",
    "layer = list(hls_model.get_layers())[1]\n",
    "\n",
    "# Print the layer's name\n",
    "print(f\"Layer Name: {layer.name}\")\n",
    "\n",
    "# Print the configuration for this layer\n",
    "print(\"\\nLayer Configuration:\")\n",
    "hls_config['LayerName'][layer.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319c0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "In file included from firmware/myproject.cpp:3:\n",
      "firmware/myproject.h:15:1: error: expected identifier before ‘)’ token\n",
      "   15 | );\n",
      "      | ^\n",
      "firmware/myproject.cpp:10:1: error: expected identifier before ‘)’ token\n",
      "   10 | ) {\n",
      "      | ^\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to compile project \"myproject\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhls_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/model/graph.py:695\u001b[39m, in \u001b[36mModelGraph.compile\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compile the generated project and link the library into current environment.\u001b[39;00m\n\u001b[32m    691\u001b[39m \n\u001b[32m    692\u001b[39m \u001b[33;03mUsers should call this function if they want to use `predict` functionality for simulation.\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    694\u001b[39m \u001b[38;5;28mself\u001b[39m.write()\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/model/graph.py:698\u001b[39m, in \u001b[36mModelGraph._compile\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     lib_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._top_function_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m platform.system() == \u001b[33m\"\u001b[39m\u001b[33mLinux\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/backends/fpga/fpga_backend.py:174\u001b[39m, in \u001b[36mFPGABackend.compile\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret_val.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mprint\u001b[39m(ret_val.stdout)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFailed to compile project \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel.config.get_project_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    175\u001b[39m lib_name = \u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m/firmware/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.so\u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m    176\u001b[39m     model.config.get_output_dir(), model.config.get_project_name(), model.config.get_config_value(\u001b[33m'\u001b[39m\u001b[33mStamp\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    177\u001b[39m )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m lib_name\n",
      "\u001b[31mException\u001b[39m: Failed to compile project \"myproject\""
     ]
    }
   ],
   "source": [
    "hls_model.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
