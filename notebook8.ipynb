{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdc67597",
   "metadata": {},
   "source": [
    "# First notebook with Python3.11\n",
    "## Load the qonnx model and convert it to an hls model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b0989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607ff7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"qonnx_fragm_model.onnx\"\n",
    "qonnx_model = ModelWrapper(model_path)\n",
    "qonnx_model = qonnx_model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e7a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quant_0_out0 \t None\n",
      "Quant_1_out0 \t None\n",
      "Quant_2_out0 \t None\n",
      "Quant_3_out0 \t None\n",
      "Quant_4_out0 \t None\n",
      "Quant_5_out0 \t None\n",
      "Quant_6_out0 \t None\n",
      "Quant_7_out0 \t None\n",
      "Quant_8_out0 \t None\n",
      "Quant_9_out0 \t None\n",
      "Quant_10_out0 \t None\n",
      "Quant_11_out0 \t None\n",
      "Quant_12_out0 \t None\n",
      "Quant_13_out0 \t None\n",
      "Quant_14_out0 \t None\n",
      "Quant_15_out0 \t None\n",
      "Quant_16_out0 \t None\n",
      "Quant_18_out0 \t None\n",
      "Quant_20_out0 \t None\n",
      "Quant_22_out0 \t None\n",
      "Quant_24_out0 \t None\n",
      "Quant_26_out0 \t None\n",
      "Quant_0_param0 \t [[ 0.06250022  0.5577103   0.6580341  -0.30759785 -0.0625      0.01789291\n",
      "  -0.3003776   0.8579889   0.23061544 -0.06250002]\n",
      " [ 0.2651383  -0.06940328 -0.20276465 -0.2140242  -0.47837278 -0.00883478\n",
      "  -0.03249751 -0.18734269 -0.19695011 -0.14357752]\n",
      " [ 0.36388516  0.7971166  -0.06250001  0.02010438 -0.2018491  -0.22834489\n",
      "  -0.16547625 -0.11273177 -0.20502089 -0.14397922]\n",
      " [-0.01069489 -0.7401072  -0.38623008 -0.13522461  0.4371471  -0.03681573\n",
      "   0.5296957   0.3122466  -0.25804794  0.32838267]\n",
      " [ 0.12197313  0.77057177  0.38337928  0.20639358  0.3128031  -0.02835875\n",
      "   0.06250001  0.3685349   0.07072204  0.00612214]\n",
      " [-0.73702145  1.0341966   0.41261542 -0.1607976   0.10895515  0.5054093\n",
      "   0.24440892  0.90506655  0.06250001 -0.04784077]\n",
      " [ 0.1030103  -0.21455318  0.19132076  0.07119951 -0.54935783  0.84715444\n",
      "  -0.2928572   0.253711   -0.54377854  0.22915366]\n",
      " [ 0.43749997 -0.30366212  0.08709523  0.06714374 -0.0625      0.31903934\n",
      "   0.08008114  0.98369616  0.06400891  0.13351347]\n",
      " [ 0.13255864  0.31701738  0.4897019   0.25224847 -0.19752604  0.56250006\n",
      "   0.06360793  0.8233261  -0.23280546  0.2135343 ]]\n",
      "Quant_0_param1 \t 0.125\n",
      "Quant_0_param2 \t 0\n",
      "Quant_0_param3 \t 6\n",
      "Quant_1_param0 \t [-0.23654169  0.48852444  0.18217349 -0.18749997  0.32763824  0.58058435\n",
      "  0.2095279   0.45758     0.05264513  0.06249994]\n",
      "Quant_1_param3 \t 10\n",
      "Quant_2_param0 \t [[ 0.7153493  -0.03859963 -0.4990396  -0.957825    0.15767293 -0.16790305\n",
      "   0.5257652   0.7495255   0.0226175 ]\n",
      " [ 0.7712443  -0.55444276  0.0625     -0.16841398  0.42810345  0.18382339\n",
      "  -0.12211723 -0.10836431  0.5353663 ]\n",
      " [ 0.9509606   0.06180532  0.06947143  0.19884184  0.46174654  0.1938174\n",
      "  -0.25853503 -0.220816    0.2830393 ]\n",
      " [ 0.10446757 -0.56573266  0.72931725  0.47807527  0.07711083  0.35163903\n",
      "  -0.31250006 -0.53795147 -0.14561449]\n",
      " [-0.28356966 -0.37430868  0.68604463  0.34417954  0.8962288   0.8516191\n",
      "   0.26636803  0.27296016 -0.17352818]\n",
      " [ 0.2090729  -0.18044868  1.0739053  -0.52882725  0.14527698  0.48413864\n",
      "   0.18353216  0.13049415  0.77361685]]\n",
      "Quant_3_param0 \t [ 0.42791742 -0.02814487  0.4573217   0.30332676  0.5619452   0.8018686\n",
      "  0.3712497   0.70390815  0.503357  ]\n",
      "Quant_4_param0 \t [[-0.34328005 -0.55270624 -1.1488727  -0.9190967  -0.81540275 -0.93731123]\n",
      " [ 0.464271   -0.25399837 -0.18749999  0.56250006  0.31008527 -0.22803143]\n",
      " [ 0.10182643  0.29807696 -0.312337    0.18750006  0.06224955 -0.06250004]\n",
      " [ 0.05384292  0.45054552 -0.42039815  0.15724698  0.06128779 -0.06250002]]\n",
      "Quant_5_param0 \t [0.44198656 0.57239676 0.5743821  0.37004054 0.34997013 0.7247995 ]\n",
      "Quant_6_param0 \t [[-0.5844939  -0.18749999  0.18749993 -0.05760292]\n",
      " [ 1.0175136  -0.19200705 -0.0657502  -0.13249971]\n",
      " [ 0.44908154 -0.04280013 -0.61224306  0.33361256]\n",
      " [ 0.3673522  -0.00659556 -0.67377627  0.5869156 ]\n",
      " [ 0.19277307 -0.66696584 -0.13831595  0.5180003 ]\n",
      " [-0.23552671  0.00453745 -0.3031349   0.06249847]]\n",
      "Quant_7_param0 \t [ 0.16960137  0.4191823  -0.11082771  0.06250001]\n",
      "Quant_8_param0 \t [[ 0.14159153 -0.09171481  0.49104625  0.36837822  0.06116361 -0.13528822]\n",
      " [-0.54052705 -0.43750006 -0.6164645  -0.41166273 -0.3794486   0.6705046 ]\n",
      " [ 0.3008941  -0.2086212  -0.6302519   0.18088232 -0.08690461 -0.23398325]\n",
      " [ 0.5346984   0.16373943 -0.58180004  0.14265622  0.29542056  0.06250001]\n",
      " [-0.23034851  0.06250001 -0.45542756 -0.6755293   0.31024694 -0.39766365]\n",
      " [ 0.45300734 -0.10241248  0.20444703 -0.12906265 -0.4553766  -0.22007829]\n",
      " [ 0.24056207 -0.33958352  0.29654825 -0.16235764  0.14564751 -0.13408035]\n",
      " [-0.36386183  0.22526826 -0.55783975 -0.3767178  -1.0274934   0.0432316 ]\n",
      " [-0.1073451   0.40567696  0.52286726  0.23258027 -0.5536042  -0.18971443]]\n",
      "Quant_9_param0 \t [-0.15041983  0.43275622  0.         -0.0235011  -0.25697732  0.04255071]\n",
      "Quant_10_param0 \t [[ 0.17038584 -0.04614829  0.4128369   0.40358865 -0.03682679 -0.22675945\n",
      "  -0.2739979   0.4538938  -0.17474009]\n",
      " [ 0.26940617  0.28071818 -0.37920418  0.0107759  -0.1544812   0.07778867\n",
      "  -0.16756631 -0.20058028  0.3150008 ]\n",
      " [-0.38388458 -0.06867948  0.40169275 -0.02703605 -0.21003906  0.418496\n",
      "  -0.370307   -0.06063513  0.21426985]\n",
      " [-0.5023136  -0.19884752  0.4803774  -0.27888426  0.04908324  0.37772623\n",
      "   0.5336265   0.49255833 -0.52145934]\n",
      " [-0.49372557 -0.1087946  -0.04645443  0.05435869 -0.27806577  0.03019653\n",
      "  -0.22972849 -0.02900162  0.2580252 ]\n",
      " [-0.12829147 -0.28682432 -0.59692824  0.02734635  0.18267502 -0.4424859\n",
      "   0.03299735 -0.25499278 -0.28394148]\n",
      " [-0.5216328   0.13717376 -0.37095386  0.2816848   0.33653158  0.2914103\n",
      "  -0.37205195  0.20460112  0.28142178]\n",
      " [ 0.05845183  0.1265137  -0.10795722  0.4375      0.20230556  0.08234656\n",
      "   0.06221524  0.498951   -0.35673982]\n",
      " [ 0.53447354 -0.442735    0.44390112  0.46892366  0.21309033 -0.290908\n",
      "  -0.30793825 -0.19207568 -0.06356401]\n",
      " [-0.01638122  0.20509371  0.03931698  0.24027145  0.2187338   0.57088643\n",
      "  -0.10306872  0.29355937  0.12365002]]\n",
      "Quant_11_param0 \t [-0.11548142 -0.11984771 -0.11891745 -0.15148105  0.26598915 -0.17495859\n",
      " -0.20843713  0.42592177  0.11578859]\n",
      "Quant_12_param0 \t [[ 0.30115086 -0.3866129  -0.21303646 -0.2623502   0.2956786   0.06235084\n",
      "   0.46013606 -0.18750139  0.10657199 -0.17222798]\n",
      " [-0.20890424  0.39966378  0.19735211 -0.2868307   0.17543818 -0.16965994\n",
      "  -0.0538659   0.26808056 -0.3614555   0.34935248]\n",
      " [-0.12082592  0.21631944  0.40684825 -0.03457487 -0.22791432  0.28172484\n",
      "   0.3555942   0.28238124 -0.00318328  0.34335354]\n",
      " [ 0.15773411  0.06249976 -0.17915998  0.17570528 -0.10644851 -0.02761998\n",
      "  -0.10026083 -0.0564224  -0.01732023 -0.15601493]\n",
      " [-0.37797296  0.47087747  0.24335292 -0.3603655  -0.06247955 -0.08930877\n",
      "  -0.14487544  0.49811912 -0.08659177 -0.1605512 ]\n",
      " [-0.17864661  0.4159627   0.06249961  0.02813028 -0.1051951   0.0053616\n",
      "  -0.18254107  0.32927352  0.04453474 -0.45573837]\n",
      " [-0.35980415  0.35540947  0.06250037 -0.01222273 -0.04853779  0.00221491\n",
      "   0.2077765  -0.21048324 -0.1312056  -0.06250046]\n",
      " [-0.22389418  0.06250005 -0.08487    -0.31831327 -0.26108313 -0.06249961\n",
      "  -0.13106236  0.17991757 -0.18984884 -0.24752548]\n",
      " [-0.37924966 -0.18749955  0.28057364 -0.05499468  0.10582565  0.26010382\n",
      "   0.00752687  0.3137555  -0.31794468  0.35679442]\n",
      " [-0.36649227  0.4342274   0.20720032 -0.23231472 -0.09141905 -0.05097915\n",
      "  -0.35155967  0.098867   -0.06668295 -0.2888775 ]\n",
      " [ 0.00806879  0.11358497 -0.06250076 -0.12873596  0.27474827  0.03157629\n",
      "  -0.11157387  0.18748964  0.17765096 -0.02531164]\n",
      " [-0.04724508  0.06247177 -0.18702388 -0.05771817  0.06522824 -0.31242058\n",
      "   0.31709656  0.3073975   0.13550217  0.06774201]\n",
      " [-0.05814432  0.20428123  0.32099554 -0.13347572 -0.25712758  0.2644536\n",
      "  -0.3400066   0.31400514  0.14371963  0.10233766]\n",
      " [-0.02368387  0.22474782 -0.20507081  0.12564942  0.22495447 -0.2712302\n",
      "  -0.23684932  0.06260822 -0.27483332  0.04422954]\n",
      " [-0.39305937 -0.2666558  -0.13250016 -0.03161253  0.06500575  0.11608732\n",
      "   0.31255528  0.4067694   0.12902361 -0.08274419]\n",
      " [-0.34137702 -0.01230914  0.0854559  -0.16727468  0.0468092  -0.13479416\n",
      "   0.4158132  -0.04818797 -0.38309833  0.4126473 ]\n",
      " [-0.19324128  0.19156677  0.33094156 -0.33496487 -0.24472877  0.35539955\n",
      "  -0.07688659  0.45322424  0.24605756  0.19358835]\n",
      " [ 0.15670049 -0.18791145 -0.06249997  0.265335   -0.29610777  0.23116401\n",
      "   0.00800142  0.31099328 -0.31480452 -0.05105892]\n",
      " [ 0.27947676 -0.09954953  0.16561294 -0.06988975  0.22797923  0.23643523\n",
      "   0.31249678  0.3376161   0.15462497 -0.02792204]\n",
      " [ 0.26865107 -0.33241886 -0.02118461 -0.05255841  0.07562481 -0.07633267\n",
      "  -0.20623733  0.14373605 -0.17189944  0.206566  ]\n",
      " [-0.34699404  0.33626202  0.0745528  -0.09667127 -0.12128107  0.03915144\n",
      "   0.08557925  0.44582868  0.1046607  -0.15064025]\n",
      " [-0.24740791  0.0473771   0.07546302 -0.26873815  0.39997116 -0.03242329\n",
      "   0.39135218 -0.06235056 -0.00189548  0.04509051]\n",
      " [-0.17579967  0.40502027  0.4043107   0.14140595 -0.255088    0.3125\n",
      "  -0.11038478  0.3074862   0.07918362  0.00818371]\n",
      " [-0.30693308  0.17521024  0.18135779 -0.16905504  0.18627535  0.22365366\n",
      "  -0.08544089  0.2609529  -0.07446497 -0.02772731]\n",
      " [-0.17611277 -0.00120733  0.02312838 -0.2230563  -0.18613328  0.15127537\n",
      "   0.45979893 -0.12376482 -0.38742518  0.40727356]\n",
      " [-0.0063388   0.29136255 -0.12761642 -0.02864767  0.24122456 -0.08343225\n",
      "   0.00299034  0.04305087 -0.3164438  -0.29481152]\n",
      " [ 0.1752262   0.61782986  0.24164408 -0.21516666 -0.0420864   0.24247766\n",
      "  -0.1040686   0.46154398 -0.3043165  -0.33611384]\n",
      " [ 0.08153296 -0.2897241   0.00222361 -0.27241406 -0.2552079   0.29143986\n",
      "  -0.32081598 -0.06892529 -0.02902443  0.19302309]\n",
      " [ 0.18273284  0.14797215  0.18387908 -0.3178217  -0.2473484   0.21158592\n",
      "   0.26451015 -0.23040679 -0.22494936  0.27874604]]\n",
      "Quant_13_param0 \t [-0.07322878  0.33799988 -0.0627002  -0.0755455  -0.06356127 -0.05897903\n",
      " -0.14493446 -0.0828503  -0.12636413 -0.07229009]\n",
      "Quant_14_param0 \t [[ 0.20493662 -0.07259513  0.07825267 ... -0.3124937   0.225153\n",
      "  -0.14394127]\n",
      " [-0.08932392 -0.03686228  0.06217164 ...  0.3142891  -0.11494439\n",
      "   0.08186166]\n",
      " [ 0.04057825  0.20749958 -0.155183   ...  0.09481017 -0.18156905\n",
      "   0.08980244]\n",
      " ...\n",
      " [ 0.05537188 -0.12426064  0.05934008 ... -0.02633424 -0.11313088\n",
      "  -0.056398  ]\n",
      " [-0.01672547 -0.05248648 -0.15275289 ...  0.24379793  0.05819669\n",
      "  -0.08998439]\n",
      " [-0.02643817  0.01449593  0.01787861 ... -0.18609278  0.04742324\n",
      "  -0.1335153 ]]\n",
      "Quant_15_param0 \t [-0.01262035  0.02276868 -0.06217779  0.14933187  0.22860706  0.31849933\n",
      "  0.02482581  0.2377816   0.01647712  0.24532568 -0.05841018 -0.06254943\n",
      "  0.16631849  0.05059179 -0.0637797   0.05432022  0.07212082 -0.06249464\n",
      " -0.03733967 -0.0548787   0.05742909  0.01888401  0.1543976  -0.08828584\n",
      " -0.03784374  0.10221691  0.33365983  0.09212759 -0.1445029 ]\n",
      "Quant_16_param0 \t 0.0625\n",
      "MatMul_0_out0 \t None\n",
      "Add_0_out0 \t None\n",
      "Relu_0_out0 \t None\n",
      "Quant_17_out0 \t None\n",
      "MatMul_1_out0 \t None\n",
      "Add_1_out0 \t None\n",
      "Relu_1_out0 \t None\n",
      "Quant_19_out0 \t None\n",
      "MatMul_2_out0 \t None\n",
      "Add_2_out0 \t None\n",
      "Relu_2_out0 \t None\n",
      "Quant_21_out0 \t None\n",
      "MatMul_3_out0 \t None\n",
      "Add_3_out0 \t None\n",
      "Relu_3_out0 \t None\n",
      "Quant_23_out0 \t None\n",
      "MatMul_4_out0 \t None\n",
      "Add_4_out0 \t None\n",
      "MatMul_5_out0 \t None\n",
      "Add_5_out0 \t None\n",
      "Relu_4_out0 \t None\n",
      "Quant_25_out0 \t None\n",
      "MatMul_6_out0 \t None\n",
      "Add_6_out0 \t None\n",
      "Relu_5_out0 \t None\n",
      "Quant_27_out0 \t None\n",
      "MatMul_7_out0 \t None\n",
      "Add_7_out0 \t None\n",
      "Sub_0_out0 \t None\n",
      "Identity_0_out0 \t None\n",
      "Quant_1_param1 \t 0.125\n",
      "Quant_1_param2 \t 0\n",
      "Quant_2_param1 \t 0.125\n",
      "Quant_2_param2 \t 0\n",
      "Quant_2_param3 \t 6\n",
      "Quant_3_param1 \t 0.125\n",
      "Quant_3_param2 \t 0\n",
      "Quant_3_param3 \t 10\n",
      "Quant_4_param1 \t 0.125\n",
      "Quant_4_param2 \t 0\n",
      "Quant_4_param3 \t 6\n",
      "Quant_5_param1 \t 0.125\n",
      "Quant_5_param2 \t 0\n",
      "Quant_5_param3 \t 10\n",
      "Quant_6_param1 \t 0.125\n",
      "Quant_6_param2 \t 0\n",
      "Quant_6_param3 \t 6\n",
      "Quant_7_param1 \t 0.125\n",
      "Quant_7_param2 \t 0\n",
      "Quant_7_param3 \t 10\n",
      "Quant_8_param1 \t 0.125\n",
      "Quant_8_param2 \t 0\n",
      "Quant_8_param3 \t 6\n",
      "Quant_9_param1 \t 0.125\n",
      "Quant_9_param2 \t 0\n",
      "Quant_9_param3 \t 10\n",
      "Quant_10_param1 \t 0.125\n",
      "Quant_10_param2 \t 0\n",
      "Quant_10_param3 \t 6\n",
      "Quant_11_param1 \t 0.125\n",
      "Quant_11_param2 \t 0\n",
      "Quant_11_param3 \t 10\n",
      "Quant_12_param1 \t 0.125\n",
      "Quant_12_param2 \t 0\n",
      "Quant_12_param3 \t 6\n",
      "Quant_13_param1 \t 0.125\n",
      "Quant_13_param2 \t 0\n",
      "Quant_13_param3 \t 10\n",
      "Quant_14_param1 \t 0.125\n",
      "Quant_14_param2 \t 0\n",
      "Quant_14_param3 \t 6\n",
      "Quant_15_param1 \t 0.125\n",
      "Quant_15_param2 \t 0\n",
      "Quant_15_param3 \t 10\n",
      "Quant_16_param1 \t 0\n",
      "Quant_16_param2 \t 10\n",
      "Quant_17_param0 \t 0.0625\n",
      "Quant_17_param1 \t 0\n",
      "Quant_17_param2 \t 10\n",
      "Quant_18_param0 \t 0.0625\n",
      "Quant_18_param1 \t 0\n",
      "Quant_18_param2 \t 10\n",
      "Quant_19_param0 \t 0.0625\n",
      "Quant_19_param1 \t 0\n",
      "Quant_19_param2 \t 10\n",
      "Quant_20_param0 \t 0.0625\n",
      "Quant_20_param1 \t 0\n",
      "Quant_20_param2 \t 10\n",
      "Quant_21_param0 \t 0.0625\n",
      "Quant_21_param1 \t 0\n",
      "Quant_21_param2 \t 10\n",
      "Quant_22_param0 \t 0.0625\n",
      "Quant_22_param1 \t 0\n",
      "Quant_22_param2 \t 10\n",
      "Quant_23_param0 \t 0.0625\n",
      "Quant_23_param1 \t 0\n",
      "Quant_23_param2 \t 10\n",
      "Quant_24_param0 \t 0.0625\n",
      "Quant_24_param1 \t 0\n",
      "Quant_24_param2 \t 10\n",
      "Quant_25_param0 \t 0.0625\n",
      "Quant_25_param1 \t 0\n",
      "Quant_25_param2 \t 10\n",
      "Quant_26_param0 \t 0.0625\n",
      "Quant_26_param1 \t 0\n",
      "Quant_26_param2 \t 10\n",
      "Quant_27_param0 \t 0.0625\n",
      "Quant_27_param1 \t 0\n",
      "Quant_27_param2 \t 10\n",
      "global_in \t None\n",
      "global_out \t None\n"
     ]
    }
   ],
   "source": [
    "tensor_list = qonnx_model.get_all_tensor_names()\n",
    "for ten_name in tensor_list:\n",
    "    print(ten_name, '\\t',qonnx_model.get_initializer(ten_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3800ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input: \"Add_0_out0\"\n",
       "input: \"Quant_16_param0\"\n",
       "input: \"Quant_16_param1\"\n",
       "input: \"Quant_16_param2\"\n",
       "output: \"Quant_16_out0\"\n",
       "name: \"Quant_16\"\n",
       "op_type: \"Quant\"\n",
       "attribute {\n",
       "  name: \"narrow\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}\n",
       "attribute {\n",
       "  name: \"rounding_mode\"\n",
       "  s: \"ROUND\"\n",
       "  type: STRING\n",
       "}\n",
       "attribute {\n",
       "  name: \"signed\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}\n",
       "domain: \"qonnx.custom_op.general\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qonnx_model.graph.node[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e79ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "308f7eac",
   "metadata": {},
   "source": [
    "End of qonnx model exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407cce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Quant_0 ['Quant_0_param0', 'Quant_0_param1', 'Quant_0_param2', 'Quant_0_param3']\n",
      "1 Quant_1 ['Quant_1_param0', 'Quant_1_param1', 'Quant_1_param2', 'Quant_1_param3']\n",
      "2 Quant_2 ['Quant_2_param0', 'Quant_2_param1', 'Quant_2_param2', 'Quant_2_param3']\n",
      "3 Quant_3 ['Quant_3_param0', 'Quant_3_param1', 'Quant_3_param2', 'Quant_3_param3']\n",
      "4 Quant_4 ['Quant_4_param0', 'Quant_4_param1', 'Quant_4_param2', 'Quant_4_param3']\n",
      "5 Quant_5 ['Quant_5_param0', 'Quant_5_param1', 'Quant_5_param2', 'Quant_5_param3']\n",
      "6 Quant_6 ['Quant_6_param0', 'Quant_6_param1', 'Quant_6_param2', 'Quant_6_param3']\n",
      "7 Quant_7 ['Quant_7_param0', 'Quant_7_param1', 'Quant_7_param2', 'Quant_7_param3']\n",
      "8 Quant_8 ['Quant_8_param0', 'Quant_8_param1', 'Quant_8_param2', 'Quant_8_param3']\n",
      "9 Quant_9 ['Quant_9_param0', 'Quant_9_param1', 'Quant_9_param2', 'Quant_9_param3']\n",
      "10 Quant_10 ['Quant_10_param0', 'Quant_10_param1', 'Quant_10_param2', 'Quant_10_param3']\n",
      "11 Quant_11 ['Quant_11_param0', 'Quant_11_param1', 'Quant_11_param2', 'Quant_11_param3']\n",
      "12 Quant_12 ['Quant_12_param0', 'Quant_12_param1', 'Quant_12_param2', 'Quant_12_param3']\n",
      "13 Quant_13 ['Quant_13_param0', 'Quant_13_param1', 'Quant_13_param2', 'Quant_13_param3']\n",
      "14 Quant_14 ['Quant_14_param0', 'Quant_14_param1', 'Quant_14_param2', 'Quant_14_param3']\n",
      "15 Quant_15 ['Quant_15_param0', 'Quant_15_param1', 'Quant_15_param2', 'Quant_15_param3']\n",
      "16 MatMul_0 ['global_in', 'Quant_14_out0']\n",
      "17 Add_0 ['MatMul_0_out0', 'Quant_15_out0']\n",
      "18 Quant_16 ['Add_0_out0', 'Quant_16_param0', 'Quant_16_param1', 'Quant_16_param2']\n",
      "19 Relu_0 ['Quant_16_out0']\n",
      "20 Quant_17 ['Relu_0_out0', 'Quant_17_param0', 'Quant_17_param1', 'Quant_17_param2']\n",
      "21 MatMul_1 ['Quant_17_out0', 'Quant_12_out0']\n",
      "22 Add_1 ['MatMul_1_out0', 'Quant_13_out0']\n",
      "23 Quant_18 ['Add_1_out0', 'Quant_18_param0', 'Quant_18_param1', 'Quant_18_param2']\n",
      "24 Relu_1 ['Quant_18_out0']\n",
      "25 Quant_19 ['Relu_1_out0', 'Quant_19_param0', 'Quant_19_param1', 'Quant_19_param2']\n",
      "26 MatMul_2 ['Quant_19_out0', 'Quant_10_out0']\n",
      "27 Add_2 ['MatMul_2_out0', 'Quant_11_out0']\n",
      "28 Quant_20 ['Add_2_out0', 'Quant_20_param0', 'Quant_20_param1', 'Quant_20_param2']\n",
      "29 Relu_2 ['Quant_20_out0']\n",
      "30 Quant_21 ['Relu_2_out0', 'Quant_21_param0', 'Quant_21_param1', 'Quant_21_param2']\n",
      "31 MatMul_3 ['Quant_21_out0', 'Quant_8_out0']\n",
      "32 Add_3 ['MatMul_3_out0', 'Quant_9_out0']\n",
      "33 Quant_22 ['Add_3_out0', 'Quant_22_param0', 'Quant_22_param1', 'Quant_22_param2']\n",
      "34 Relu_3 ['Quant_22_out0']\n",
      "35 Quant_23 ['Relu_3_out0', 'Quant_23_param0', 'Quant_23_param1', 'Quant_23_param2']\n",
      "36 MatMul_4 ['Quant_23_out0', 'Quant_6_out0']\n",
      "37 Add_4 ['MatMul_4_out0', 'Quant_7_out0']\n",
      "38 MatMul_5 ['Add_4_out0', 'Quant_4_out0']\n",
      "39 Add_5 ['MatMul_5_out0', 'Quant_5_out0']\n",
      "40 Quant_24 ['Add_5_out0', 'Quant_24_param0', 'Quant_24_param1', 'Quant_24_param2']\n",
      "41 Relu_4 ['Quant_24_out0']\n",
      "42 Quant_25 ['Relu_4_out0', 'Quant_25_param0', 'Quant_25_param1', 'Quant_25_param2']\n",
      "43 MatMul_6 ['Quant_25_out0', 'Quant_2_out0']\n",
      "44 Add_6 ['MatMul_6_out0', 'Quant_3_out0']\n",
      "45 Quant_26 ['Add_6_out0', 'Quant_26_param0', 'Quant_26_param1', 'Quant_26_param2']\n",
      "46 Relu_5 ['Quant_26_out0']\n",
      "47 Quant_27 ['Relu_5_out0', 'Quant_27_param0', 'Quant_27_param1', 'Quant_27_param2']\n",
      "48 MatMul_7 ['Quant_27_out0', 'Quant_0_out0']\n",
      "49 Add_7 ['MatMul_7_out0', 'Quant_1_out0']\n",
      "50 Sub_0 ['Add_7_out0', 'Quant_19_out0']\n",
      "51 Identity_0 ['Sub_0_out0']\n",
      "52 Identity_1 ['Identity_0_out0']\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(qonnx_model.model.graph.node):\n",
    "    print(i, node.name, node.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fb47d",
   "metadata": {},
   "source": [
    "### Convert to an HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hls4ml.utils.config import config_from_onnx_model\n",
    "from hls4ml.converters import convert_from_onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4370db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n"
     ]
    }
   ],
   "source": [
    "hls_config = config_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    granularity='name',\n",
    "    backend='Vitis',\n",
    "    default_precision='fixed<16,6>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca263ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2744e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b30c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b049412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model ...\n",
      "Output layers:  ['Identity_1']\n",
      "Input shape: [57]\n",
      "Topology:\n",
      "Layer name: Quant_0, layer type: Quant, current shape: [[9, 10]]\n",
      "Layer name: Quant_1, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_2, layer type: Quant, current shape: [[6, 9]]\n",
      "Layer name: Quant_3, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_4, layer type: Quant, current shape: [[4, 6]]\n",
      "Layer name: Quant_5, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_6, layer type: Quant, current shape: [[6, 4]]\n",
      "Layer name: Quant_7, layer type: Quant, current shape: [[4]]\n",
      "Layer name: Quant_8, layer type: Quant, current shape: [[9, 6]]\n",
      "Layer name: Quant_9, layer type: Quant, current shape: [[6]]\n",
      "Layer name: Quant_10, layer type: Quant, current shape: [[10, 9]]\n",
      "Layer name: Quant_11, layer type: Quant, current shape: [[9]]\n",
      "Layer name: Quant_12, layer type: Quant, current shape: [[29, 10]]\n",
      "Layer name: Quant_13, layer type: Quant, current shape: [[10]]\n",
      "Layer name: Quant_14, layer type: Quant, current shape: [[57, 29]]\n",
      "Layer name: Quant_15, layer type: Quant, current shape: [[29]]\n",
      "Layer name: MatMul_0, layer type: MatMul, current shape: [[1, 57], [57, 29]]\n",
      "Layer name: Add_0, layer type: Merge, current shape: [[1, 29], [29]]\n",
      "Layer name: Quant_16, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: Relu_0, layer type: Activation, current shape: [[1, 29]]\n",
      "Layer name: Quant_17, layer type: Quant, current shape: [[1, 29]]\n",
      "Layer name: MatMul_1, layer type: MatMul, current shape: [[1, 29], [29, 10]]\n",
      "Layer name: Add_1, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Quant_18, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: Relu_1, layer type: Activation, current shape: [[1, 10]]\n",
      "Layer name: Quant_19, layer type: Quant, current shape: [[1, 10]]\n",
      "Layer name: MatMul_2, layer type: MatMul, current shape: [[1, 10], [10, 9]]\n",
      "Layer name: Add_2, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_20, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_2, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_21, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_3, layer type: MatMul, current shape: [[1, 9], [9, 6]]\n",
      "Layer name: Add_3, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_22, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_3, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_23, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_4, layer type: MatMul, current shape: [[1, 6], [6, 4]]\n",
      "Layer name: Add_4, layer type: Merge, current shape: [[1, 4], [4]]\n",
      "Layer name: MatMul_5, layer type: MatMul, current shape: [[1, 4], [4, 6]]\n",
      "Layer name: Add_5, layer type: Merge, current shape: [[1, 6], [6]]\n",
      "Layer name: Quant_24, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: Relu_4, layer type: Activation, current shape: [[1, 6]]\n",
      "Layer name: Quant_25, layer type: Quant, current shape: [[1, 6]]\n",
      "Layer name: MatMul_6, layer type: MatMul, current shape: [[1, 6], [6, 9]]\n",
      "Layer name: Add_6, layer type: Merge, current shape: [[1, 9], [9]]\n",
      "Layer name: Quant_26, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: Relu_5, layer type: Activation, current shape: [[1, 9]]\n",
      "Layer name: Quant_27, layer type: Quant, current shape: [[1, 9]]\n",
      "Layer name: MatMul_7, layer type: MatMul, current shape: [[1, 9], [9, 10]]\n",
      "Layer name: Add_7, layer type: Merge, current shape: [[1, 10], [10]]\n",
      "Layer name: Sub_0, layer type: Merge, current shape: [[1, 10], [1, 10]]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv_3_11/lib64/python3.11/site-packages/hls4ml/model/optimizer/passes/move_scales.py:93: UserWarning: Failed to propagate quantization scales down MatMul node; model probably not suppored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "qonnx_model = qonnx_model.cleanup()\n",
    "hls_model = convert_from_onnx_model(\n",
    "    qonnx_model,\n",
    "    output_dir='hls_model8',\n",
    "    io_type='io_stream',    # default is 'io_parallel'\n",
    "    backend='Vitis',\n",
    "    hls_config=hls_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1b41c",
   "metadata": {},
   "source": [
    "### Look at the uncompiled HLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bad3c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parse_qonnx': {'fuse_quant_with_constant',\n",
       "   'matmul_const_to_dense',\n",
       "   'merge_to_apply_alpha',\n",
       "   'quant_constant_parameters',\n",
       "   'quant_to_activation',\n",
       "   'scale_down_mat_mul'},\n",
       "  'convert': {'fuse_batch_normalization',\n",
       "   'infer_precision_types',\n",
       "   'merge_linear_activation'},\n",
       "  'optimize': set(),\n",
       "  'vivado:init_layers': {'vivado:init_base_layer', 'vivado:init_dense'},\n",
       "  'vitis:validation': set(),\n",
       "  'vivado:streaming': {'vivado:clone_output'},\n",
       "  'vivado:quantization': set(),\n",
       "  'vivado:optimize': set(),\n",
       "  'vivado:specific_types': {'vivado:register_bram_weights',\n",
       "   'vivado:set_pipeline_style',\n",
       "   'vivado:transform_types'},\n",
       "  'vitis:apply_templates': {'vitis:activation_hardactivation_softmax_function_template',\n",
       "   'vitis:activation_unarylut_config_template',\n",
       "   'vitis:dense_config_template',\n",
       "   'vitis:dense_function_template',\n",
       "   'vitis:merge_concatenate_dot_function_template',\n",
       "   'vitis:merge_config_template'},\n",
       "  'vivado:apply_templates': {'vivado:activation_hardactivation_softmax_function_template',\n",
       "   'vivado:activation_unarylut_config_template',\n",
       "   'vivado:clone_function_template',\n",
       "   'vivado:dense_config_template',\n",
       "   'vivado:dense_function_template',\n",
       "   'vivado:merge_concatenate_dot_function_template',\n",
       "   'vivado:merge_config_template'},\n",
       "  'vitis:ip': set()}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model._applied_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23a8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394c000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _layer_name in hls_model.graph.keys():\n",
    "    layer_dicts.append(hls_model.graph.get(_layer_name).__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b83f8958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_data': array([[ 0.20493662, -0.07259513,  0.07825267, ..., -0.3124937 ,\n",
       "          0.225153  , -0.14394127],\n",
       "        [-0.08932392, -0.03686228,  0.06217164, ...,  0.3142891 ,\n",
       "         -0.11494439,  0.08186166],\n",
       "        [ 0.04057825,  0.20749958, -0.155183  , ...,  0.09481017,\n",
       "         -0.18156905,  0.08980244],\n",
       "        ...,\n",
       "        [ 0.05537188, -0.12426064,  0.05934008, ..., -0.02633424,\n",
       "         -0.11313088, -0.056398  ],\n",
       "        [-0.01672547, -0.05248648, -0.15275289, ...,  0.24379793,\n",
       "          0.05819669, -0.08998439],\n",
       "        [-0.02643817,  0.01449593,  0.01787861, ..., -0.18609278,\n",
       "          0.04742324, -0.1335153 ]], shape=(57, 29), dtype=float32),\n",
       " 'weight_quantizer': <hls4ml.model.quantizers.QuantNodeQuantizer at 0x7f2c651ba750>,\n",
       " 'bias_data': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'use_bias': False,\n",
       " 'n_in': np.int64(57),\n",
       " 'n_out': np.int64(29),\n",
       " 'index': 173,\n",
       " 'accum_t': <hls4ml.backends.fpga.fpga_types.HLSNamedType at 0x7f2c651c3a10>,\n",
       " 'trace': False,\n",
       " 'precision': {'result': 'auto', 'accum': 'auto'},\n",
       " 'reuse_factor': 1,\n",
       " 'result_t': <hls4ml.backends.fpga.fpga_types.HLSPackedType at 0x7f2c671191d0>,\n",
       " 'MatMul_0_out0': <hls4ml.backends.fpga.fpga_types.VivadoStreamVariable at 0x7f2c651c3bd0>,\n",
       " 'weight_t': <hls4ml.backends.fpga.fpga_types.HLSNamedType at 0x7f2c651d83d0>,\n",
       " 'weight': <hls4ml.backends.fpga.fpga_types.StaticWeightVariable at 0x7f2c65246290>,\n",
       " 'bias_t': <hls4ml.backends.fpga.fpga_types.HLSNamedType at 0x7f2c651d85d0>,\n",
       " 'bias': <hls4ml.backends.fpga.fpga_types.StaticWeightVariable at 0x7f2c657ac7d0>,\n",
       " 'quantizer': <hls4ml.model.quantizers.QuantNodeQuantizer at 0x7f2cb0305bd0>,\n",
       " 'target_cycles': None,\n",
       " 'strategy': 'latency',\n",
       " 'index_t': <hls4ml.backends.fpga.fpga_types.HLSNamedType at 0x7f2c6710d5d0>,\n",
       " 'config_cpp': 'struct config173 : nnet::dense_config {\\n    static const unsigned n_in = 57;\\n    static const unsigned n_out = 29;\\n    static const unsigned io_type = nnet::io_stream;\\n    static const unsigned strategy = nnet::latency;\\n    static const unsigned reuse_factor = 1;\\n    static const unsigned n_zeros = 546;\\n    static const unsigned n_nonzeros = 1107;\\n    static const unsigned multiplier_limit = DIV_ROUNDUP(n_in * n_out, reuse_factor) - n_zeros / reuse_factor;\\n    static const bool store_weights_in_bram = false;\\n    typedef Dense_MatMul_0_accum_t accum_t;\\n    typedef bias173_t bias_t;\\n    typedef weight173_t weight_t;\\n    typedef layer173_index index_t;\\n    template<class data_T, class res_T, class CONFIG_T>\\n    using kernel = nnet::DenseLatency<data_T, res_T, CONFIG_T>;\\n    template<class x_T, class y_T>\\n    using product = nnet::product::mult<x_T, y_T>;\\n};\\n',\n",
       " 'include_header': ['nnet_utils/nnet_dense.h',\n",
       "  'nnet_utils/nnet_dense_compressed.h',\n",
       "  'nnet_utils/nnet_dense_stream.h'],\n",
       " 'function_cpp': 'nnet::dense<input_t, layer173_t, config173>(global_in, layer173_out, w173, b173);'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.graph.get('Dense_MatMul_0').attributes.attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b599879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('global_in',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisInput at 0x7f2c67119190>),\n",
       "             ('Dense_MatMul_0',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651c3850>),\n",
       "             ('Relu_0',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c6519eb50>),\n",
       "             ('Dense_MatMul_1',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d4490>),\n",
       "             ('Relu_1',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c651a4350>),\n",
       "             ('clone_Relu_1',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisClone at 0x7f2c651d7a50>),\n",
       "             ('Dense_MatMul_2',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d4ed0>),\n",
       "             ('Relu_2',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c651a5d10>),\n",
       "             ('Dense_MatMul_3',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d5510>),\n",
       "             ('Relu_3',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c651a7710>),\n",
       "             ('Dense_MatMul_4',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d5e90>),\n",
       "             ('Dense_MatMul_5',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d6850>),\n",
       "             ('Relu_4',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c651adbd0>),\n",
       "             ('Dense_MatMul_6',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d7150>),\n",
       "             ('Relu_5',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisActivation at 0x7f2c651af510>),\n",
       "             ('Dense_MatMul_7',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisDense at 0x7f2c651d7b50>),\n",
       "             ('Sub_0',\n",
       "              <hls4ml.backends.fpga.fpga_backend.VitisMerge at 0x7f2c651b49d0>)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf405c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_expected_attributes',\n",
       " '_set_accum_t',\n",
       " '_set_type_t',\n",
       " '_validate_attributes',\n",
       " '_wrap_precision_to_type',\n",
       " '_wrapped',\n",
       " 'add_bias',\n",
       " 'add_output_variable',\n",
       " 'add_weights',\n",
       " 'add_weights_variable',\n",
       " 'attributes',\n",
       " 'class_name',\n",
       " 'code',\n",
       " 'expected_attributes',\n",
       " 'get_attr',\n",
       " 'get_input_node',\n",
       " 'get_input_variable',\n",
       " 'get_layer_precision',\n",
       " 'get_output_nodes',\n",
       " 'get_output_use_map',\n",
       " 'get_output_variable',\n",
       " 'get_variables',\n",
       " 'get_weights',\n",
       " 'index',\n",
       " 'initialize',\n",
       " 'inputs',\n",
       " 'model',\n",
       " 'name',\n",
       " 'outputs',\n",
       " 'set_attr',\n",
       " 'types',\n",
       " 'variables',\n",
       " 'weights']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hls_model.graph.get(_layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71c1ec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <hls4ml.model.graph.ModelGraph at 0x7f2c6513cd90>,\n",
       " 'name': 'Relu_1',\n",
       " 'index': 126,\n",
       " 'inputs': ['MatMul_1_out0'],\n",
       " 'outputs': ['Relu_1_out0'],\n",
       " 'attributes': <hls4ml.model.attributes.AttributeDict at 0x7f2c65170f90>,\n",
       " 'weights': <hls4ml.model.attributes.WeightMapping at 0x7f2c651a4490>,\n",
       " 'variables': <hls4ml.model.attributes.VariableMapping at 0x7f2c651a4650>,\n",
       " 'types': <hls4ml.model.attributes.TypeMapping at 0x7f2c651a4690>,\n",
       " 'code': <hls4ml.model.attributes.CodeMapping at 0x7f2c651a46d0>}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dicts[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
