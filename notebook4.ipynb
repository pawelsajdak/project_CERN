{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8259f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 17:34:15.197014: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-18 17:34:15.931759: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-18 17:34:15.931858: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-18 17:34:15.935311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-18 17:34:16.344016: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-18 17:34:16.347504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-18 17:34:53.218793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import h5py\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from qkeras import quantized_bits\n",
    "co = {}; _add_supported_quantized_objects(co)\n",
    "\n",
    "model_path = f\"/eos/project/c/cms-l1ml/public/Pawel/axol1tl_model.h5\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=co)\n",
    "#model_config = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc05754",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"/eos/project/c/cms-l1ml/public/Pawel/complete.h5\"\n",
    "data_file = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ed723",
   "metadata": {},
   "source": [
    "### Copying weights into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb95ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b78776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_weights = data_file['model']['trimmed_encoder']['model_weights']\n",
    "for layer in iter(model.layers):\n",
    "    #print(layer.name)\n",
    "    if layer.name in ('input_1','subtract','dot'): continue\n",
    "\n",
    "    if layer.name == 'q_dense_4':\n",
    "        weights_group = ds_weights['q_dense_4']['variational_auto_encoder']['vae__encoder']['q_dense_4']\n",
    "        layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))\n",
    "        continue\n",
    "\n",
    "    weights_group = ds_weights[layer.name][layer.name]\n",
    "    layer.set_weights((weights_group['kernel:0'], weights_group['bias:0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29da8c",
   "metadata": {},
   "source": [
    "### Test with background data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72cfe64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_file['data'][\"Background_data\"][\"Test\"][\"DATA\"][:]\n",
    "\n",
    "input_quantizer = quantized_bits(14, 5, alpha=1)\n",
    "output_quantizer = quantized_bits(18,13,alpha=1)\n",
    "bias_quantizer = quantized_bits(18,12,alpha=1)\n",
    "\n",
    "X = X.reshape(X.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4113a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:  25%|██▌       | 2/8 [00:00<00:00, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds:  62%|██████▎   | 5/8 [00:00<00:00, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qkeras preds: 100%|██████████| 8/8 [00:00<00:00, 20.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 128\n",
    "pred_qkeras = []\n",
    "\n",
    "for start in tqdm(range(0, 1024, batch_size), desc=\"Qkeras preds\"):\n",
    "        end = min(start + batch_size, 1024)\n",
    "        \n",
    "        pred = model.predict(input_quantizer(X[start:end]))\n",
    "        quantized_pred = output_quantizer(pred)\n",
    "        pred_qkeras.append(quantized_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655c2ac",
   "metadata": {},
   "source": [
    "### Conversion to a QONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35cda9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cern.ch/user/p/psajdak/eos_mine/project_CERN/venv3_9/lib64/python3.9/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "2025-08-18 18:04:14.654024: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2025-08-18 18:04:14.654208: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2025-08-18 18:04:14.711346: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2025-08-18 18:04:14.711493: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n"
     ]
    }
   ],
   "source": [
    "import qonnx.core.onnx_exec as oxe\n",
    "from qonnx.converters import from_keras\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "qonnx_model, external_storage = from_keras(model)\n",
    "qonnx_model = ModelWrapper(qonnx_model)\n",
    "qonnx_model = qonnx_model.transform(InferShapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fff544ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [01:16<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_qonnx = []\n",
    "\n",
    "for i in tqdm(range(0, 128)):\n",
    "    idict = {qonnx_model.graph.input[0].name: input_quantizer(X[i]).numpy().reshape(1,57)}\n",
    "    odict = oxe.execute_onnx(qonnx_model, idict, True)\n",
    "    pred = output_quantizer(odict[qonnx_model.graph.output[0].name])\n",
    "    pred_qonnx.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "08d74ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.4375  1.375   1.75    0.8125  4.875   3.75    4.1875  2.25    0.8125\n",
      "  3.8125  0.9375  0.3125  5.1875  1.      8.4375  1.25    2.125   0.75\n",
      "  2.125   1.625   2.1875  3.375   2.5     1.5     2.      3.0625  2.375\n",
      "  1.5625  2.25    2.      1.375   0.6875  1.      0.875   1.      0.8125\n",
      "  1.625   2.125   2.1875  1.75    1.4375  0.8125  3.625   0.75    1.375\n",
      "  2.125   4.25    1.75    0.875   1.875   1.6875  3.      3.      1.4375\n",
      "  1.375   0.9375  1.0625  1.5     2.625   1.5     0.875   3.6875  1.5\n",
      "  0.6875  2.375   1.3125  4.375   0.875   2.875   2.0625  2.5     0.5\n",
      "  1.1875  1.25    6.125   0.6875  1.5625  0.875   1.3125  0.6875  1.5625\n",
      "  1.5     2.625   1.5625  0.5     1.25    2.5     2.0625  0.3125  2.625\n",
      "  1.5625  1.25    0.9375  2.75    1.875   0.75    1.5     2.5625  0.75\n",
      "  7.625   6.5     1.6875  1.375   0.9375  4.375   3.25    4.1875  0.5625\n",
      "  2.9375  2.5     2.25    0.5625  1.9375  2.875   3.25    2.5625  1.0625\n",
      "  2.3125  0.5625 13.0625  1.125   1.4375  3.75    0.625   0.625   2.9375\n",
      "  3.625   0.8125]\n"
     ]
    }
   ],
   "source": [
    "print(pred_qkeras[0].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c99d39c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4136963]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_qonnx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "811ed8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4375 4.4375]\n",
      " [1.375  1.375 ]\n",
      " [1.75   1.75  ]\n",
      " [0.8125 0.8125]\n",
      " [4.875  4.875 ]\n",
      " [3.75   3.75  ]\n",
      " [4.1875 4.1875]\n",
      " [2.25   2.25  ]\n",
      " [0.8125 0.8125]\n",
      " [3.8125 3.8125]]\n"
     ]
    }
   ],
   "source": [
    "pred_qonnx = numpy.array(pred_qonnx)\n",
    "print(numpy.hstack((pred_qkeras[0].numpy()[:10], pred_qonnx[:10].reshape(-1,1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
